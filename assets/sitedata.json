


{
  "pages": [
    {
      
      
      
      "content": "\n",
      "url": "/404.html"
    },{
      
      "title": "Blog",
      "description": "Random thoughts and musings on technology, design, and curiosities.\n",
      "content": "\n",
      "url": "/blog/"
    },{
      
      "title": "A Little About Me",
      
      "content": "\n",
      "url": "/"
    },{
      
      "title": "Posts",
      "description": "This is the list layout for showing blog posts, which shows just the title and groups them by year of publication. Check out the blog layout for comparison.\n",
      "content": "\n",
      "url": "/posts/"
    },{
      
      "title": "My Experiments",
      "description": "Here’s what I’ve been working on. Take a look if you’re interested.\n",
      "content": "\n",
      "url": "/projects/"
    },{
      
      "title": "A List of My Studiousness",
      "description": "Some papers that I wrote and helped with.\n",
      "content": "\n",
      "url": "/research/"
    },{
      
      "title": "Résumé*",
      "description": "David Jr Sim’s current resume.\n",
      "content": "\n",
      "url": "/resume/"
    }
  ], 
  "documents": [
    {
      
      "title": "Collaborative Development Style",
      "date": "2023-09-30 00:00:00 +0000",
      
      "content": "No man walks alone. Nowhere is that truer than for a developer. From the most prominent organizations to the smallest startups, standardization is a key tool in ensuring code quality and maintainability. Even if you’re a solo developer, the future you will still have to deal with the choice present you make. Every developer has experienced a time where they had to unravel their past coding choices when revisiting old codebases and projects. Code style, code smells, and development styles measurably increase bug-catch rates and help with workflow [1]. This truth translates to the environment surrounding your code base.\n\n\n  Why be in Style?\n  Each Team’s Fashion Sense\n  Commiting to the Style    \n      Overall Format        \n          Type\n          Scope\n          Exclamation\n          Commit Message Description\n          Body and Footer\n          Owner\n        \n      \n    \n  \n  Coding in Style    \n      LCC (Lower Camel Case) Supremacy\n      Bracket Brakes\n      Unused Imports Need to Go\n    \n  \n  Fashionable Issues    \n      Small Issues\n      Large Issues\n      Issue Template Explanation        \n          Issue Title\n          Issue Title Description\n          Replication\n          Other Information*\n        \n      \n      Issue Template\n    \n  \n  Perfect Pull Requests    \n      Pull Request Template Explanation        \n          Pull Request Title\n          Overview\n          Screenshots (Optional)\n          Feedback Request (Optional)\n          Future Possibilities (Optional)\n          Validation (Optional)\n          Tests\n          Linked Issues\n        \n      \n      Pull Request Template\n    \n  \n  Code Reviews    \n      Responding to a Code Review\n      Code Review Checklist\n    \n  \n  Conclusion\n  References\n\n\nWhy be in Style?\n\nEven if you are a solo developer, having a consistent style to easily search, understand, and reference what is happening is critical as you build your portfolio. Understanding someone else’s codebase (or simply relearning your old one) is hard enough; don’t add to the confusion by making commit messages inconsistent, pipelines untracable, or documentation hard to find. A logical and well-defined workflow will make you and your team more productive.\n\nEach Team’s Fashion Sense\n\nThere are too many styles, practices, guidelines, and philosophies to list and present. If I were to try to include them all to explain, this would be under Research, or I would tell you to go read Agile. Instead, I want to present a starting point for your team’s exploration, research, and evolution. I will explain my rationale for each choice and how it has helped my team in our development. This style is based around Git and GitHub but can be adapted to any version control system or ecosystem.\n\nIf you’ve never tried to follow a style, I encourage you to start here. I find it flexible enough to introduce you to some concepts while not limiting you to a rigid set of rules.\n\nCommiting to the Style\n\nWe will start with the most basic item: commit messages. It goes without saying that all commits should be small and incremental. Hopefully, they are atomic enough for the codebase to utilize the true power of Git. Yet, when it is time to go and commit, you need to explain to someone what you changed without them having to look at the code. In this style, we use Conventional Commits (CC) as the foundation for our commit messages. Its website has a great FAQ about why you should use it. TLDR: It helps with automation, documentation, and understanding. For someone with no previous preferences in their messages, this ensures a versatile beginning to be adapted wherever your journey takes you. While the specification isn’t too long, I will summarize the important parts here.\n\nOverall Format\n\nThe overall format of a commit message is:\n\n&lt;type&gt;[optional (scope)][optional !]: &lt;description&gt;\n\n[optional body]\n\n[optional footer(s)]\n\n\nLet’s go through each part one by one.\n\nType\n\nThis is the “category” of your change. It really can be any set that your team agrees on. However, as per CC, the two most common ones are feat (adding new code) and fix (fixing old code).\n\nSome more common types that are defined are:\n\n  docs: Changes in documentation or comments\n  style: Everything related to styling (of code and not application)\n  refactor: Changes that neither fix a bug nor add a feature\n  test: Everything related to testing (i.e., when creating a test suite and not modifying a file to pass tests)\n  chore: Everything related to maintaining the code (e.g., updating build tasks, package manager configs, etc)\n\n\nScope\n\nThis is an optional field that can be useful when your codebase is large. It defines the area of impact for your change. For example, if you are working on a full-stack application, you might have client, server, database, etc. You can also make it more granular. Say your app has multiple microservices, you could have auth, payment, notification, etc. Just remember that the scope will be in parentheses, i.e., (auth).\n\nExclamation\n\nThis is an optional character that helps denote a breaking change. It is most commonly used when moving from version 1 to version 2 or when an external dependency changes.\n\nCommit Message Description\n\nThis is the “title” of your commit. It should inform the reader broadly of what you’ve changed. As a general rule, it should be less than 25 words; any more than that, and it should be in the body.\n\nDo not end it with a punctuation mark, as it is not a sentence. Plus, it’s an extra character that will forever be in your history. Over time, they add up.\n\nStart your title with an imperative tense word (e.g., add and not added or adds). This makes it neutral and easier to understand. In addition, capitalize only the first word to denote the start of the description sentence (e.g., feat:Compute ray render). This wording style may seem picky at first, but when someone is reading through hundreds of commit histories, it makes the process easier to scan and digest.\n\nSome may find it helpful to think of the description as completing the sentence: “After this commit, the application will…”. Contrast that with “In this commit, I will…”. At the end of the day, you are simply the medium through which the code is changed. Your actions and process are not important; the code is. You will not perform the application functions; the code will, so make the message about the code (e.g., not feat:Add database handler but feat:Openfacing database api).\n\nBody and Footer\n\nThese are both optional fields. I slightly discourage using these fields as we have integrated better ways of expressing these fields through Github. However, if your team is on a pure Git workflow, I recommend reading more about them on CC’s website.\n\nOwner\n\nIn today’s day and age, computer security is more important than ever[2][3]. As such, each person should have all their commits signed with their GPG key. That isn’t to say that these referenced CVE cases could’ve been solved by this. Rather, GPG is another layer of security to lock down any potential leaks in your codebase. Plus, it just looks cool. Thus, you should utilize the tools Github offers you and add your GPG key.\n\nFor those environments where code change attribution is necessary, add the initials of programmers at the end of the description to give credit to the authors when group programming (e.g., feat:describe a description-(ds/jz/pm)). Note the hyphen, lack of spaces, and parentheses between the description and initials. If group members’ initials are the same, utilize the hierarchy below until there is no ambiguity (e.g., (dos/jz/pm/dss)):\n\n  Middle name initial\n  Middle name letters\n  Last name letters\n  First name letters\n\n\nCoding in Style\n\nOkay, I know this post is about everything around the code, but I would be remiss if I didn’t mention a few overarching items that apply broadly. Don’t forget, there are too many code linters, formatters, plugins, and tools to help you with this section. However, here are some basics that I believe in.\n\nLCC (Lower Camel Case) Supremacy\n\nIn line with the “punctuations add unnecessary characters” theme, I believe underscores do the same. One can easily read a variable name through LCC, and it saves on character count and finger strokes. Is there a place for underscores? Maybe, but it is definitely not in your variable names.\n\nBracket Brakes\n\nThe first bracket should be on the same line. I don’t know why you would have a bracket on its own line. That’s not how to extend your lines-of-code-written stat. It takes up a useless line and, in my personal opinion, looks a little dumb and incomplete.\n\n// file: `correct.cpp`\nfor(int 0; i &lt;= streetLength; i++) {\n  walkTheDog();\n}\n\n\n// file: `bad.cpp`\nfor(int 0; i &lt; sillyModeMax; i++) \n{\n  beBad();\n}\n\n\nUnused Imports Need to Go\n\nWhile I may be a hoarder in real life, there’s no need to hoard your dependencies in your codebase. It will still be there the next time you need to use it. Unused imports bloat your code, make it harder to understand, and create gaps for security vulnerabilities. REMOVE. UNUSED. IMPORTS. Better yet, minimize your imports. You don’t need the is-thirteen library.\n\nFashionable Issues\n\nIssues are the main reason why we collaborate on code. If we all wrote perfect code, who would want to deal with another person? As such, issues need to be documented and transferable between members. Here, we define two categories of issues: small and large.\n\nBoth categories incorporate all types of issues (i.e., bugs, vulnerabilities, etc.).\n\nSmall Issues\n\nThese small issues can be solved within 10 minutes and can be described within 100 words.\n\nBoth of these conditions must be met for it to be considered a small issue. If it can be described in less than 100 words but cannot be fixed within 10 minutes, then it is not a small issue. Likewise, if it can be fixed within 10 minutes but is so nuanced that 100 words cannot tell the whole story, then it is not a small issue.\n\nSuch small issues should be relayed across team members through non-codebase channels (e.g., Slack, Discord, etc.). This will prevent clustering of issues, say on Github, and preserve such places for more critical, team-wide considerations. That is not to say that these small issues are any less important. Never should an issue in an existing codebase be fixed by a single person. You never know when and where it will be called, and if your fix breaks compatibility, it will be a nightmare domino effect.\n\nLarge Issues\n\nThese issues encompass anything that small issues cannot. More literally, if you need to write documentation on the issue, or even issue a press release, then it is a large issue. These issues should be documented on Github through the Issues tab and need to be more thoroughly described. This way, the entire team can work on the issue and be on the same page. Below is a very minimal but adaptable template. Because there are an infinite number of ways an issue can arise, I have chosen to include only the bones. Feel free to adapt and modify this template for your codebase.\n\nIssue Template Explanation\n\nIssue Title\n\nThis is the summary of the issue. It should be descriptive but no more than 10 words. Think of this like the description in a commit message.\n\nIssue Title Description\n\nThis is the actual details of the issue. It should include all relevant details of the issue and why it is not working as expected. Some people also include expected behavior and actual behavior subsections. If you get a colleague to read nothing else but this section, and they have no idea what the issue is, then you did it wrong. While detailed, it should also be brief, no more than three paragraphs. Any more than this, and you have multiple issues on your hands.\n\nReplication\n\nThis is where you document how to reproduce the issue. Think of this almost as a copy-and-paste installation section on Github. I should be able to run everything you’ve described here without thinking and reproduce the problem.\n\nOther Information*\n\nThis is where you include everything else related to the issue. It has an asterisk because it is the most adaptable part of this template. Add subsections, links, and anything else you deem fit. I personally would include platform and system versions, screenshots, and maybe even videos.\n\nIssue Template\n\n&lt;!--file: `.github/ISSUE_TEMPLATE/basic.md`--&gt;\n## Description\n&lt;!--A paragraph explaining the issue.--&gt;\nLorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n\n## Replication\n&lt;!--What steps are needed to reproduce this issue?--&gt;\nLorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n\n## Other Information\n&lt;!--Any other related information that someone trying to debug this issue needs to know.--&gt;\nLorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi\n\n\nPerfect Pull Requests\n\nPull requests are the backbone of Git collaboration. It is how code is accepted into the application, it is how work is measured, it is how progress is completed. There really aren’t (or shouldn’t be) that many types of pull request varieties. With it being so universal across all projects, this template is a little more thorough compared to issues. Regardless, feel free to adapt it to your needs.\n\nPull Request Template Explanation\n\nPull Request Title\n\nAgain, this is like the description of a commit message, with 10 words or less. Can someone familiar with the project understand precisely what is being added?\n\nOverview\n\nThis should summarize all the commits in the pull request and should also follow the 3-paragraph rule. Not only does this limit encourage brevity, but it also helps as a sanity check that the one pull request is not trying to add too much to the codebase. You shouldn’t be doubling the codebase in one pull request. You should also go into more detail about the specific changes made in the pull request so that someone familiar with the project can understand all the changes exactly. It should include details from the programmer, admin, and user perspectives. If there is a working instance (e.g., a dev branch or a demo), link it here as well.\n\nScreenshots (Optional)\n\nIf the change has a visual component, include a screenshot. This allows for reviewer to quickly glance at the proposed addition without the need to spin up their own instance. If needed, flex those markdown skills and add captions to the images for clarity. I will also add that if you are committing frontend visual changes, then you should treat this section as non-optional.\n\nFeedback Request (Optional)\n\nIf the pull request is a work in progress or if there are code sections that a reviewer should pay attention to, mention it here. Don’t be shy and egotistic; ask for help if you need it. If there is a specific person who should pay attention, add them here to get their attention. You should be specific about the types of feedback you are looking for and not just general feedback. (e.g., “I am looking for feedback on the new API calls and if we need more granular control” or “Dave, please help me review my implementation of the matching algorithm and its speed”). You should be competent enough not to require a classroom-level review.\n\nFuture Possibilities (Optional)\n\nThis section is a somewhat pathos section of approving this merge. Talk about the big picture or reiterate the necessity of this change to remind people of its big-picture purpose. Be as comprehensible as required, but do not put your grandeur dreams first. This is not a place to pitch your next big idea.\n\nValidation (Optional)\n\nIf there isn’t a demo instance, what steps are necessary to reproduce your feature to check that it works? Start by checking out your branch and then interacting with the app. It doesn’t have to be complicated, but like the replication section of the issues template, it should be easy to follow mindlessly. If nothing else, treat this section as if you were talking with your end user.\n\nTests\n\nThis is a checklist-style of all the standard tests your pull request has passed. They should not include any CD/CI tests that will run (e.g., github workflows). Instead, they should be manual tests that must be passed before the pull request can be merged. This suite of tests should be standardized by the team. If there are additional one-off tests, make sure they are clearly marked. If there are any failed tests, call them out and, if necessary, explain why they are necessarily failing.\n\nLinked Issues\n\nMost, if not all, pull requests should be linked to an issue. This is a feature of Github, but regardless, the issue prompting this pull request should be referenced somewhere. This is a great way to keep track of progress and automatically remove completed issues during CD/CI. That said, try to limit each pull request to one issue. This ensures your request is not too large and heavy on the codebase. If you need to link multiple issues, link one issue per line for readability. On Github, you can link an issue by using any of the following magic words plus #issueNo:\n\n\n  close\n  closes\n  closed\n  fix\n  fixes\n  fixed\n  resolve\n  resolves\n  resolved\n\n\nPull Request Template\n\n&lt;!--file: `.github/PULL_REQUEST_TEMPLATE/basic.md`--&gt;\n## Overview\n&lt;!--A paragraph of the PR and related content--&gt;\nLorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n\n## Screenshots (Optional)\n&lt;!--Necessary screenshots and any necessary captions here. Delete if not needed.--&gt;\n![Generic placeholder image](https://picsum.photos/640/480)\n\n## Feedback Request (Optional)\n&lt;!--Anywhere specific you want reviewers to take a look at and give suggestions. Delete if not needed.--&gt;\nNone needed. I am the best.\n\n## Future Possibilities (Optional)\n&lt;!--What do you think this project could become? Delete if not needed.--&gt;\nThis will go to the moon if we invest all our life savings into this concept!!!\n\n## Validation (Optional)\n&lt;!--Steps that someone else could take to make sure everything is working--&gt;\nJust trust me, bro. :)\n\n## Tests\n&lt;!--Add any additional tests or required tests--&gt;\n- [ ] Unit tests pass\n- [ ] Test coverage is at 100%\n- [ ] Mutation tests show a rate of 100% \n\n## Linked Issues\n&lt;!--Issues related to the PR--&gt;\nCloses #0\n\n\nCode Reviews\n\nA simple “LGTM!” is NOT A CODE REVIEW! It is a sign of laziness and, in my experience, one of the leading ways issues get leaked to production. Instead, the reviewer should pay attention to the code changes and not rely automatically on the CD/CI environment.\n\nBelow is a checklist to help guide you with some starting questions to consider when doing a code review. It is not an exhaustive list, but it should be mostly included in any review.\n\nWrite any issues or suggestions that you may have to the requestor and have those issues changed before approving. Remember to be constructive and respectful with your review. They took the time to code everything, after all. We are all learning, so have open discussions about your suggestions and provide guidance if necessary. Make sure your suggestions and criteria are straightforward for the requestor to go and fix. Your code review is not done until you approve of the PR, so respond to any changes and updates within a reasonable time frame!\n\nResponding to a Code Review\n\nBe positive and open a discussion. You do not have to implement or agree with other people’s decisions. Respond from a point of gratitude- they took the time to look over your code, after all. If you agree, write something to acknowledge their feedback(e.g., “good call, fixed” or “thanks for catching that, fixed”). If you don’t, open a discussion with them and see how to resolve the issue; don’t just dismiss the comment (e.g., “Hmm, I see it differently; let’s discuss” or “I’m not sure I understand your perspective; can you explain further?” or “I see where you are coming from, but i/we think it should be like this…”).\n\nCode Review Checklist\n\n\n  Is the PR conforming to the standards described within this document?\n  Are there relevant sections (e.g., screenshots for frontend, test coverage,e and mutation for all)\n  Is the purpose of the PR well explained, not just the what, but also the why?\n  If there is a linked issue, is the assigned issue coder in the loop with this PR (i.e., the PR requestor or approves the PR)?\n  Does the PR pass all of the CI/CD tests?\n  When applicable, is there a deployed dev instance to test, and does it work?\n  If the issue(s) this PR addresses have acceptance criteria, are all of those met? And if so, are they checked off?\n  Commented out code; typically, this should be removed before merging into the default branch.\n  Quickly look at the file changes and see if any stand out and should be removed (e.g., .DS_Store from Mac users or *~ from emacs users or package.json and package-lock.json at the top level of the repo (they should only be in the frontend directory)\n\n\nConclusion\n\nThat wasn’t so bad, was it? The simplified documentation on our discussion can be found here. Now, go on and explore, adapt, and break all the rules you deem fit. Just remember to document your changes.\n\nReferences\n[1]\nA. Cairo, G. Carneiro, and M. Monteiro, “The Impact of Code Smells on Software Bugs: A Systematic Literature Review,” Information, vol. 9, no. 11, p. 273, Nov. 2018, doi: https://doi.org/10.3390/info9110273.\n\n[2]\nCVE-2021-44228 (Log4j2). https://nvd.nist.gov/vuln/detail/cve-2021-44228\n\n[3]\nCVE-2024-3094 (xz). https://nvd.nist.gov/vuln/detail/cve-2024-3094\n",
      "categories": [],
      "tags": [],
      
      "collection": "posts",
      "url": "/blog/2023-09-30-development-style/"
    },{
      
      "title": "Computer Science-r vs Programmer",
      "date": "2025-01-17 00:00:00 +0000",
      
      "content": "A rant to be added soon…\n",
      "categories": [],
      "tags": [],
      
      "collection": "posts",
      "url": "/blog/2025-01-17-computer-sciencer-vs-programmer/"
    },{
      
      "title": "Port My Environment",
      "date": "2025-07-27 00:00:00 +0000",
      
      "content": "I spin up and shut down servers constantly, whether it’s for testing, for fun, or for necessity, I find myself with a dilemma. Either I can invest the time in migrating over my preferred environment to save time down the road, or I can take the efficiency loss and work with a minimal and inconvenient terminal. I want to choose neither. Thus, like all good programmers, I spent way too long automating the process of porting my setup.\n\n\n  VBox    \n      The Testing Workflow\n    \n  \n  The Script    \n      Prerequisite        \n          Let the Managers Manage\n        \n      \n      Subroutines        \n          Installers            \n              MacOS\n              Linux\n              Extendable\n            \n          \n          TOML Helper\n          Transitions\n          Basic Printing\n          User Interaction\n          Logging\n        \n      \n      Setup        \n          OS Detection\n          Pretty Print\n        \n      \n      Main        \n          Git &amp; SSH\n          Main Package Manager\n          ZSH\n          NodeJS\n          Rush\n          Python\n          Make\n          MacOS Defaults\n          Tmux\n          RESH\n          Chruby\n          Chezmoi\n          Homebrew\n        \n      \n      Cleanup\n    \n  \n  Conclusion\n\n\nVBox\n\nIt is in these low-level projects that the power of virtualization really shines. From the start of my coding days, my goto solution has been Oracle’s VirtualBox. It is free, open-source, cross-platform, and without any bloat. Critically, for me, it is compatible with my M-series MacBook.\n\nAs I refuse to do anything in Powershell, this script will assume I have not lost my mind and am in a Unix environment. Because I like jellyfishes, I am using Ubuntu as my base OS for this project. However, the script will extend to the other major distributions, including MacOS. Using the ISO, I set up a basic installation of Ubuntu with a shared folder to my host machine. This is now my base image that I will copy for each iteration and test for my script.\n\nThe Testing Workflow\n\nWith my CD/CI pipeline set up, I can now focus on the actual developonment of the script. My testing workflow is now as follows:\n\n\n  Make sure the current version of the script is in the shared folder.\n  Spin up a copy of the base image.\n  Test the script.\n  Rinse and repeat.\n\n\nIt cannot get any simpler. No more setting up fresh environments or worries of contamination from previous tests. Once I have my script in an acceptable state, I can adjust the base image to other distributions and test again.\n\nThe Script\n\nFor the sake of universality, I have sacrilegiously chosen bash as the language. As such we must chant the spell at the beginning that will protect us from its curses:\n\n#!/usr/bin/env bash\n\nset -euo pipefail\n\n\nPrerequisite\n\nBefore touching the script, you need a list of the packages you want to install. It doesn’t have to be exhaustive, but it should cover the essentials and get your environment to a comfortable state.\n\nLet the Managers Manage\n\nThere are countless package managers nowadays with robust features. Why reinvent the wheel? If the package manager can handle you dependencies, then let it. If it doesn’t need a standalone installation, don’t make it harder than it needs to be. This script is designed to leverage package managers to do the heavy lifting, so install all the managers you’ll need.\n\nAs my version of the script relies on these managers, if you choose to not install them, the script will simply exit.\n\nSubroutines\n\nFinally, with the planning phase out of the way, let’s get into the meat of the script. We will set ourselves up for success by defining the most common subroutines we will need for each installation.\n\nInstallers\n\nAs we focus on Unix systems, we will look at the two routines we’ll need: Linux and MacOS.\n\nMacOS\n\nAs MacOS’s most popular, and arguably only, package manager is Homebrew, we will define a subroutine to install packages through it.\n\n__macInstall() {\n\tlocal app=\"$1\";\n\n\tbrew install \"$app\";\n}\n\n\nLinux\n\nFor Linux, we will prioritze snap as the primary package manager, with the distribution’s native package manager as a backup. If it is a classic snap app, we will also have to specify it during the install command. Here, we choose the four horsemen of distributions to support: Debian-based (apt), RedHat-based (dnf), Arch-based (pacman), and Fedora-based (yum).\n\n__linuxInstall() {\n\tlocal app=\"$1\";\n\tlocal snap_classic=${2-\"\"};\n\n\tif [[ $(command -v snap) ]]; then\n\t\tif [[ $(snap find \"$app\" 2&gt;/dev/null | grep -c \"^$app \") -gt 0 ]]; then\n\t\t\tsudo snap install $app $snap_classic;\n\t\t\treturn 0;\n\t\tfi\n\tfi\n\n\tif [[ $(command -v apt) ]]; then # Debian/Ubuntu\n        sudo apt-get update &amp;&amp; sudo apt-get install -y $app;\n        return 0;\n    elif [[ $(command -v dnf) ]]; then # RedHat\n        sudo dnf install -y $app;\n        return 0;\n    elif [[ $(command -v yum) ]]; then # Fedora\n        sudo yum install -y $app;\n        return 0;\n    elif [[ $(command -v pacman) ]]; then # Arch\n        sudo pacman install -y $app;\n        return 0;\n    else\n        echo \"ERROR::Unsupported Linux distribution. Please install $app manually.\" &gt;&amp;2;\n        exit 2;\n    fi\n}\n\n\nExtendable\n\nTo promote extensibility, you can easily add more subroutines for other operating systems or package managers as needed. When such new subroutines are added, you can simply add them as an option to the wrapper subroutine below that will call the appropriate installer based on the detected OS.\n\n_install_() {\n\tlocal app=\"$1\";\n\tlocal snap_classic=${2-\"\"};\n\n\tcase \"$OSTYPE\" in\n\t\tlinux*)\n\t\t\t__linuxInstall \"$app\" \"$snap_classic\"\n\t\t\t;;\n\t    darwin*)\n\t\t\t__macInstall \"$app\"\n\t\t\t;;\n\tesac\n}\n\n\nTOML Helper\n\nFor one of my packages (Chezmoi), I will need to do work with TOML, and I will need to check for specific settings.\n\n__tomlLineExists() {\n\tlocal line=\"$1\";\n\tlocal section=\"$2\";\n\tlocal file=\"$3\";\n\n\tawk -v section=\"$section\" -v line=\"$line\" '\n\t\t$0 == section { in_section=1 }\n        in_section &amp;&amp; $0 == line { found=1; exit }\n        END { exit !found }\n\t' \"$file\"\n}\n\n\nTransitions\n\nI want this script to be pretty. As such, I’ve used gum to handle user interactions and display messages. This subroutine will help with transitions between different states in the script.\n\n_transition_() {\n\tlocal text=$1;\n\n\tif [[ $prettyPrint == 1 ]]; then\n\t\tgum spin --spinner line --title \"$text...\" -- sleep 1;\n\telse\n\t\techo \"$text...\";\n\t\tsleep 1;\n\tfi\n}\n\n\nBasic Printing\n\nOf course, the pretty prints and UIs are not required. For those that cannot handle the extra weight, we will simply use stdout and these subroutines to print messages. Additionally, when the script is first starting up, it will not have the ability to pretty print, so these subroutines will be used there as well.\n\n_print_() {\n\tlocal text=$1;\n\n\tif [[ $prettyPrint == 1 ]]; then\n\t\techo \"# $text\" | gum format ;\n\telse\n\t\techo \"$text\";\n\tfi\n}\n\n_print_header_() {\n\tlocal text=$1;\n\n\tif [[ $prettyPrint == 1 ]]; then\n\t\tgum style \\\n\t\t\t\t--foreground 212 --border-foreground 91 --border double \\\n\t\t\t\t--align center --width 50 --margin \"1 2\" --padding \"2 4\" \\\n\t\t\t\t\"$text\";\n\telse\n\t\techo \"##########~$text~##########\";\n\t\techo \"##################################################\";\n\tfi\n}\n\n_end_() {\n\tif [[ $prettyPrint == 1 ]]; then\n\t\tclear -x;\n\telse\n\t\techo \"##################################################\";\n\tfi\n}\n\n\nUser Interaction\n\nWe will need the user to input and confirm certain actions as this is an interactive script.\n\n_confirm_() {\n\tlocal prompt=$1;\n\n\tif [[ $prettyPrint == 1 ]]; then\n\t\tif gum confirm \"$prompt\"; then\n\t\t\treturn 0;\n\t\telse\n\t\t\treturn 1;\n\t\tfi\n\telse\n\t\tread -p \"$prompt (y/n) \" promptChoice;\n\t\tif [[ \"${promptChoice,,}\" == \"y\" || \"${promptChoice,,}\" == \"yes\" ]]; then\n\t\t\treturn 0;\n\t\telse\n\t\t\treturn 1;\n\t\tfi\n\tfi\n}\n\n_input_() {\n\tlocal placeholder=$1;\n\tif [[ $prettyPrint == 1 ]]; then\n\t\techo $(gum input --placeholder=\"$placeholder\")\n\telse\n\t\tread -p \"$placeholder: \" out;\n\t\techo \"$out\";\n\tfi\n}\n\n\nLogging\n\nAs with all good scripts, we will want to log what is and has had happened in the script.\n\n_log_() {\n\tlocal level=$1;\n\tlocal text=$2;\n\n\tif [[ $prettyPrint == 1 ]]; then\n\t\tgum log --prefix=\"[Port-My-Env]\" --structured --time=RFC850 --level=$level \"$text\" --file=\"$HOME/port-my-env.log\";\n\telse\n\t\techo \"[Port-My-Env] $(date +%Y/%m/%d-%H:%M:%S) ($level) $text\" &gt;&gt; \"$HOME/port-my-env.log\";\n\tfi\n}\n\n\nSetup\n\nWith all the subroutines defined, we can now do some quick housekeeping. Mainly, we need to check the OS compatibility and whether or not we will be using pretty printing.\n\nOS Detection\n\nFirst thing’s first, we need to detect the OS. This will determine the packages, package managers, and other configurations needed. It will also exit the script immediately if the OS is unsupported. We will inform the user, log it, and finally start the script.\n\ncase \"$OSTYPE\" in\n\tlinux*)\n\t\tosName=\"linux\"\n\t\tif [ -f /etc/lsb-release -o -d /etc/lsb-release.d ]; then # If available, use LSB to identify distribution\n    \t\texport DISTRO=$(lsb_release -i | cut -d: -f2 | sed s/'^\\t'//)\n\t\telse # Otherwise, use release info file\n    \t\texport DISTRO=$(ls -d /etc/[A-Za-z]*[_-][rv]e[lr]* | grep -v \"lsb\" | cut -d'/' -f3 | cut -d'-' -f1 | cut -d'_' -f1)\n\t\tfi\n\t\t;;\n    darwin*)\n\t\tosName=\"mac\"\n\t\t;;\n    *)\n\t\tosName=\"__invalid__\"\n\t\t;;\nesac\n\nif [[ \"$osName\" == \"__invalid__\" ]]; then\n\t_print_header_ ERROR::This script is only intended for UNIX devices.;\n\texit 1;\nfi\n\n_print_ \"We have detected that you are on a $osName device.\";\n_log_ \"info\" \"Detected linux distro: $DISTRO\";\n_log_ \"debug\" \"Starting script...\";\n\n\nPretty Print\n\nAs this script uses gum for pretty printing and user interaction, we will need to check if it is installed. If not, we will offer to install it for the user. If the user declines, we will proceed without pretty printing. Otherwise, gum has specific installation instructions based on the OS, so we will follow those and set the pretty print flag accordingly.\n\nprettyPrint=0;\nexport prettyPrint;\n\n_print_header_ \"Step 0\";\nif [[ ! $(command -v gum) ]]; then\n\t_print_ \"This script has the ability to be interactive in a pretty way.\";\n\t_print_ \"It will use gum (https://github.com/charmbracelet/gum\\) as the prettifier.\";\n\tif _confirm_ \"Would you like to install and use gum?\"; then\n\t\t# For Linux gum install\n\t\tif [[ \"$osName\" == \"linux\" ]]; then\n    \t\t# Check for Ubuntu and install\n    \t\tif [[ \"$DISTRO\" != \"Ubuntu\" ]]; then\n    \t\t\tif [[ ! $(command -v gum) ]]; then\n    \t\t\t\t_print_ \"You are on a linux distro that this script cannot automatically install gum for you.\";\n    \t\t\t\t_print_ \"Please see the Github page and install manually and then rerun the script.\";\n    \t\t\t\texit 0;\n    \t\t\tfi\n    \t\telse\n    \t\t\tsudo mkdir -p /etc/apt/keyrings;\n\t\t\t\tcurl -fsSL https://repo.charm.sh/apt/gpg.key | sudo gpg --dearmor -o /etc/apt/keyrings/charm.gpg;\n\t\t\t\techo \"deb [signed-by=/etc/apt/keyrings/charm.gpg] https://repo.charm.sh/apt/ * *\" | sudo tee /etc/apt/sources.list.d/charm.list;\n\t\t\t\tsudo apt update &amp;&amp; sudo apt install gum;\n\t\t\t\t_log_ \"info\" \"Autoinstalled gum via this script.\";\n    \t\tfi\n\t\tfi\n\n\t\t# For Mac gum install\n\t\tif [[ \"$osName\" == \"mac\" ]]; then\n\t\t\t_print_ \"Gum will be installed via Homebrew and will be deleted afterwards (if you so choose).\";\n\t\t\t_print_ \"If you have not installed Homebrew and do not want Homebrew, do not use pretty print on MacOS.\";\n\t\t\t_input_ \"Press [ENTER] to continue or CTRL+C to exit.\";\n\t\t\tif [[ ! $(command -v brew) ]]; then\n\t\t\t\tNONINTERACTIVE=1 /bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\";\n  \t\t\t\teval \"$(/opt/homebrew/bin/brew shellenv)\";\n  \t\t\tfi\n  \t\t\tHOMEBREW_NO_ENV_HINTS=1 brew install gum;\n  \t\t\t_log_ \"info\" \"Autoinstalled gum via this script.\";\n\t\tfi\n\t\tprettyPrint=1;\n\telse\n\t\tprettyPrint=0;\n\tfi\nelse\n\tif _confirm_ \"Gum has been detected on your computer. Would you like to use it for pretty print?\"; then\n\t\tprettyPrint=1;\n\telse\n\t\tprettyPrint=0;\n\tfi\nfi\n\nif [[ $prettyPrint == 1 ]]; then\n\tgum spin --spinner line --title \"Gum is being used! You should see a spinner...\" -- sleep 1;\n\t_log_ \"info\" \"Using pretty printing.\"\nelse\n\t_print_ \"No pretty printing today...\";\n\t_log_ \"info\" \"No pretty printing today.\"\n\t_end_;\n\tsleep 1;\nfi\n\n\nMain\n\nNow the moment you’ve been waiting for: let’s get to the main script.\n\nGit &amp; SSH\n\nLike with a goods things in life, it is never complete without Git and SSH. With that, these will be the first things to set up. Due to the sensitive nature of these two tools, we will not automate their setup, but rather simply remind the user to have them installed and configured.\n\n_print_header_ \"New System Environment Porting Script\";\n_print_ \"Please make sure that you have SSH and Git installed and enough configured that you can clone your private Github repos (i.e., with usable keys).\";\nif ! _confirm_ \"Are you ready to continue?\"; then\n\t_print_ \"Please rerun the script once yo've set both of them up!\";\n\t_end_;\n\texit 1;\nfi\n_log_ \"info\" \"SSH and Git configuration confirmed\";\n\nGITHUB_USERNAME=\"dscpsyl\"\nGITHUB_DOTS_REPO=\"dotfiles\"\n_print_ \"This script has your Github username as $GITHUB_USERNAME and your dotfiles repo as $GITHUB_DOTS_REPO.\";\nif ! _confirm_ \"Are these values correct?\"; then\n\tGITHUB_USERNAME=$(_input_ \"Please type the correct Github Username...\");\n\tGITHUB_DOTS_REPO=$(_input_ \"Please type the correct Github Repo Name...\");\nfi\n_log_ \"info\" \"Using Github username $GITHUB_USERNAME and gitub dotfiles repo name $GITHUB_DOTS_REPO\";\n_end_;\n\n\nMain Package Manager\n\nNow, we want to setup the main installer for all of our packages. On linux, we will ask if the user wants to autoupdate packages, and then ask to install snap. Both of these are optional, as we will already have the distro’s built-in manager, but recommended. On MacOS, we will ask to install homebrew. If this is declined, we will exit the script since MacOS has nothing else as popular.\n\n_print_header_ \"Package Manager\"\n\nif _confirm_ \"You are on a linux system. Would you like to auto-update installs?\"; then\n\tsudo dpkg-reconfigure --priority=low unattended-upgrades;\n\t_log_ \"info\" \"DPKG auto update installed packages set\";\n\t_print_ \"DPKG setting set!\";\nelse\n\t_log_ \"warn\" \"DPKG auto update installed packages skipped\";\n\t_print_ \"No auto updating packages. Got it!\";\nfi\n\nif [[ \"$osName\" == \"linux\" ]]; then\n\tif [[ ! $(command -v snap) ]]; then\n\t\t_print_ \"Snap is not installed\"\n\n\t\tif ! _confirm_ \"Do you want to install Snap now?\"; then\n\t\t\t_install_ snapd;\n\t\t\tsudo systemctl enable --now snapd.socket;\n\t\t\tsudo ln -s /var/lib/snapd/snap /snap;\n\n\t\t\t_print_ \"Snap installed successfully!\"\n  \t\t\t_log_ \"info\" \"Snap installed\";\n  \t\telse\n  \t\t\t_print_ \"Skipping Snap installation\";\n  \t\t\t_log_ \"warn\" \"Snap installation skipped\";\n\t\tfi\n\n\telse\n\t\t_print_ \"Snap found!\";\n\t\t_log_ \"info\" \"Snap is already installed on this system\";\n\tfi\nfi\n\nif [[ \"$osName\" == \"mac\" ]]; then\n\tif [[ ! $(command -v brew) ]]; then\n\t\t_print_ \"Homebrew is not installed\";\n\t\t\n\t\tif ! _confirm_ \"Do you want to install Homebrew now?\"; then\n\t\t\t_print_ \"This script requires Homebrew on MacOS to function. Exiting...\";\n\t\t\t_log_ \"fatal\" \"Homebrew instillation request denied on MacOS\";\n\t\t\texit 1;\n\t\tfi\n\n\t\tif [[ $prettyPrint == 1 ]]; then\n\t\t\tgum spin --spinner=line --show-output -- NONINTERACTIVE=1 /bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\";\n  \t\telse\n  \t\t\tNONINTERACTIVE=1 /bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\";\n  \t\tfi\n  \t\teval \"$(/opt/homebrew/bin/brew shellenv)\";\n\n  \t\t_print_ \"Homebrew installed successfully!\"\n  \t\t_log_ \"info\" \"Homebrew installed\"\n\telse\n\t\t_print_ \"Homebrew found!\";\n\t\t_log_ \"info\" \"Homebrew is already installed on this system\";\n\tfi\nfi\n_end_;\n\n\nZSH\n\nI am a cult-bliever in zsh and oh-my-zsh. Thus, I have made these required in the script. To balance out this obsession, I have chosen to make making zsh the deault shell to be optional.\n\n_print_header_ \"ZSH Default Shell\";\nif [[ \"$SHELL\" != \"/usr/bin/zsh\" ]]; then\n\tif _confirm_ \"Would you like to set ZSH as your default shell?\"; then\n\t\tUSER=$(whoami)\n\t\tchsh -s $(which zsh) $USER;\n\t\t_print_ \"ZSH set as default shell! You will be dropped into zsh the next time you log in.\";\n\t\t_log_ \"info\" \"Default shell switched to ZSH.\";\n\telse\n\t\t_print_ \"We will ignore ZSH for now!\";\n\t\t_log_ \"warn\" \"ZSH default shell switch denied.\";\n\tfi\nelse\n\t_print_ \"ZSH already default!\";\n\t_log_ \"info\" \"ZSH is already the default shell.\";\nfi\n_end_;\n\n_print_header_ \"Oh-My-ZSH\";\nif [[ ! -d \"$HOME/.oh-my-zsh\" ]]; then\n\t_print_ \"Oh-My-ZSH is not installed and is required\";\n\tif ! _confirm_ \"Do you want to install Oh-My-ZSH now?\"; then\n\t\t_print_ \"This script requires Oh-My-ZSH to function. Exiting...\";\n\t\t_log_ \"fatal\" \"Oh-My-ZSH instillation request denied\";\n\t\texit 1;\n\tfi\n\n\tRUNZSH=no sh -c \"$(curl -fsSL https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\";\n\n\t_print_ \"Oh-My-ZSH installed successfully!\"\n  \t_log_ \"info\" \"Oh-My-ZSH installed\";\nelse\n\t_print_ \"Oh-My-ZSH found!\";\n\t_log_ \"info\" \"Oh-My-ZSH is already installed on this system\";\nfi\n_end_;\n\n\nNodeJS\n\nAs much as I like to hate on javascript, there is no denying that I partake in its wine from time to time. Thus, I will need nodejs installed. I have chosen nvm as my gateway drug and it will be the required manager for nodejs.\n\nprint_header_ \"NVM and NodeJS\";\nif [[ ! -d \"$HOME/.nvm\" ]]; then\n\t_print_ \"NVM and NodeJS are not installed and are required\";\n\tif ! _confirm_ \"Would you like to install NVM (Node Version Manager) and NodeJS?\"; then\n\t\t_print_ \"This script requires NVM and NodeJS to function. Exiting...\";\n\t\t_log_ \"fatal\" \"NVM and NodeJS instillation request denied\";\n\t\texit 1;\n\tfi\n\n\tcurl -o- https://raw.githubusercontent.com/nvm-sh/nvm/master/install.sh | bash;\n\t\\. \"$HOME/.nvm/nvm.sh\";\n\tnvm install node;\n\n\t_print_ \"NVM and NodeJS installed successfully!\"\n  \t_log_ \"info\" \"NVM and NodeJS installed\";\nelse\n\tif [[ ! $(command -v node) ]]; then\n\t\t_print_ \"NVM has been found on the system but not Node.\";\n\t\t_log_ \"info\" \"NVM is already installed on this system\";\n\t\tif ! _confirm_ \"Would you like to install NodeJS with NVM?\"; then\n\t\t\t_print_ \"This script requires NodeJS to function. Please manually install it. Exiting...\";\n\t\t\t_log_ \"fatal\" \"NodeJS instillation request denied\";\n\t\t\texit 1;\n\t\tfi\n\t\tnvm install node;\n\t\t_print_ \"NodeJS installed successfully!\"\n  \t\t_log_ \"info\" \"NodeJS installed\";\n\telse\t\n\t\t_print_ \"NVM and NodeJS found!\";\n\t\t_log_ \"info\" \"NVM and NodeJS are already installed on this system\";\n\tfi\nfi\n_end_;\n\n\nRush\n\nI think rust is fine. It has its quirks, but overall it’sa comfortable language to work with. With its popularity, many of the tools I use are written in rust and on crates. Thus, having crates is another necessity.\n\n_print_header_ \"Ruby\";\nif [[ ! $(command -v ruby) ]]; then\n\t_print_ \"Ruby is not installed and is required\";\n\tif ! _confirm_ \"Do you want to install Ruby now?\"; then\n\t\t_print_ \"This script requires Ruby to function. Exiting...\";\n\t\t_log_ \"fatal\" \"Ruby instillation request denied\";\n\t\texit 1;\n\tfi\n\n\t_install_ ruby \"--classic\";\n\n\t_print_ \"Ruby installed successfully!\"\n  \t_log_ \"info\" \"Ruby installed\";\nelse\n\t_print_ \"Ruby found!\";\n\t_log_ \"info\" \"Ruby is already installed on this system\";\nfi\n_end_;\n\n\nPython\n\nGood old python. Love it. Nothing else to say here. Most of the time, it should already be installed, but just in case, we will check and install it if needed. While I like pip as much as the next guy, some tools are better off more standalone, so pipx it is.\n\n_print_header_ \"Python3\";\nif [[ ! $(command -v python3) ]]; then\n\t_print_ \"Python3 is not installed and is required\";\n\tif ! _confirm_ \"Do you want to install Python3 now?\"; then\n\t\t_print_ \"This script requires Python3 to function. Exiting...\";\n\t\t_log_ \"fatal\" \"Python3 instillation request denied\";\n\t\texit 1;\n\tfi\n\n\t_install_ python3;\n\n\t_print_ \"Python3 installed successfully!\"\n  \t_log_ \"info\" \"Python3 installed\";\nelse\n\t_print_ \"Python3 found!\";\n\t_log_ \"info\" \"Python3 is already installed on this system\";\nfi\n_end_;\n\n_print_header_ \"pipx\";\nif [[ ! $(command -v pipx) ]]; then\n\t_print_ \"pipx is not installed and is required\";\n\tif ! _confirm_ \"Do you want to install pipx now?\"; then\n\t\t_print_ \"This script requires pipx to function. Exiting...\";\n\t\t_log_ \"fatal\" \"pipx instillation request denied\";\n\t\texit 1;\n\tfi\n\n\t_install_ pipx;\n\tpipx ensurepath;\n\n\t_print_ \"pipx installed successfully!\"\n  \t_log_ \"info\" \"pipx installed\";\nelse\n\t_print_ \"pipx found!\";\n\t_log_ \"info\" \"pipx is already installed on this system\";\nfi\n_end_;\n\n\nMake\n\nThis should be on the system already, like python. It’s here more so as another just-in-case catch.\n\n_print_header_ \"make\";\nif [[ ! $(command -v make) ]]; then\n\t_print_ \"make is not installed and is required\";\n\tif ! _confirm_ \"Do you want to install make now?\"; then\n\t\t_print_ \"This script requires make to function. Exiting...\";\n\t\t_log_ \"fatal\" \"make instillation request denied\";\n\t\texit 1;\n\tfi\n\n\t_install_ make;\n\n\t_print_ \"make installed successfully!\"\n  \t_log_ \"info\" \"make installed\";\nelse\n\t_print_ \"make found!\";\n\t_log_ \"info\" \"make is already installed on this system\";\nfi\n_end_;\n\n_transition_ \"Prerequisites Sastified! Continuing\";\n_end_;\n\n\nYou may have also noticed now that its starting to get pretty repetitive. I could wrap this structure up into another sobroutine for conciseness, but I was too lazy. You can make the change yourself, or just deal with it.\n\nMacOS Defaults\n\nNow that the essential package managers are installed, let’s take a detour to MacOS land and apply my preferred defaults.\n\nif [[ \"$osName\" == \"mac\" ]]; then\n\t_print_header_ \"MacOS Defaults\";\n\tif _confirm_ \"Would you like to set the MacOS predefined defaults?\"; then\n\t\t_print_ \"Setting MacOS Dock Defaults...\";\n\t\tdefaults write com.apple.Dock autohide-delay -float 0;\n\t\tdefaults write com.apple.dock expose-animation-duration -float 0.12;\n\t\tdefaults write com.apple.Dock showhidden -bool YES;\n\t\tdefaults write com.apple.dock expose-animation-duration -float 0;\n\t\tkillall Dock;\n\t\t_log_ \"info\" \"Set MacOS Dock Defaults\";\n\n\t\t_print_ \"Setting MacOS Finder Defaults...\";\n\t\tdefaults write com.apple.finder QLEnableTextSelection -bool TRUE;\n\t\tdefaults write com.apple.finder AppleShowAllFiles -bool YES;\n\t\tdefaults write com.apple.finder FXDefaultSearchScope -string \"SCcf\";\n\t\tkillall Finder;\n\t\t_log_ \"info\" \"Set MacOS Finder Defaults\";\n\n\t\t_print_ \"Setting MacOS ScreenCapture Defaults...\";\n\t\tdefaults write com.apple.screencapture location ~/Desktop;\n\t\tdefaults write com.apple.screencapture type png &amp;&amp; killall SystemUIServer;\n\t\t_log_ \"info\" \"Set MacOS ScreenCapture Defaults\";\n\n\t\t_print_ \"Setting ~/Library/ noHidden Flag...\";\n\t\tchflags nohidden ~/Library/;\n\t\t_log_ \"info\" \"Set ~/Library/ noHidden Flag\";\n\n\t\t_print_ \"Setting MacOS to show all extensions...\";\n\t\tdefaults write -g AppleShowAllExtensions -bool true;\n\t\t_log_ \"info\" \"Set MacOS to show all extensions\";\n\n\t\t_print_ \"Setting MacOS NSGlobalDomain Defaults...\";\n\t\tdefaults write NSGlobalDomain NSNavPanelExpandedStateForSaveMode -bool true;\n\t\tdefaults write NSGlobalDomain NSNavPanelExpandedStateForSaveMode2 -bool true;\n\t\tdefaults write NSGlobalDomain PMPrintingExpandedStateForPrint -bool true;\n\t\tdefaults write NSGlobalDomain PMPrintingExpandedStateForPrint2 -bool truefloat 0.05;\n\t\t_log_ \"info\" \"Set MacOS NSGlobalDomain Defaults\";\n\n\t\t_print_ \"Setting MacOS Subpixel Anti-Aliasing (Font Smoothing)...\"\n\t\tdefaults write -g CGFontRenderingFontSmoothingDisabled -bool false;\n\t\t_log_ \"info\" \"Set MacOS Subpixel Anti-Aliasing\";\n\n\t\t_print_ \"Setting MacOS Focus Follows Mouse in Terminal...\"\n\t\tdefaults write com.apple.Terminal FocusFollowsMouse -string YES;\n\t\t_log_ \"info\" \"Set MacOS Focus Follows Mouse in Terminal\";\n\tfi\n\t_end_;\nfi\n\n\nTmux\n\nI am a tmux man. It was my first multiplexer and my home. Are there better options? Maybe; I would argue not. Are there quirks and annoyances? Of course. But it is reliable and has never failed me, unlike other multiplexers. It is not a requirement here, but I will always press yes.\n\n_print_header_ \"Tmux\"; # (https://github.com/tmux/tmux)\nif [[ ! $(command -v tmux) ]]; then\n\t_print_ \"Tmux is not installed\";\n\tif _confirm_ \"Do you want to install Tmux now?\"; then\n\t\t\n\t\t_install_ tmux;\n\n\t\t_print_ \"Tmux installed successfully!\";\n  \t\t_log_ \"info\" \"Tmux installed\";\n\telse\n\t\t_print_ \"Who needs panels anyways!\";\n\t\t_log_ \"warn\" \"Tmux installation denied\";\n\tfi\nelse\n\t_print_ \"Tmux found!\";\n\t_log_ \"info\" \"Tmux is already installed on this system\";\nfi\n_end_;\n\n\nRESH\n\nI’ve always found the basic shell history lacking. As such, here is my preferred shell history plugin.\n\n_print_header_ \"RESH (Rich Enhanced Shell History)\"; # (https://github.com/curusarn/resh)\nif [[ ! -d \"$HOME/.resh\" ]]; then\n\t_print_ \"RESH is not installed\";\n\tif _confirm_ \"Would you like to install RESH (Rich Enhanced Shell History) and set keybindings?\"; then\n\t\t\n\t\tif [[ \"$osName\" == \"mac\" ]]; then\n\t\t\tif _confirm_ \"This will also install coreutils on this Mac. Are you sure?\"; then\n\t\t\t\tbrew install coreutils;\n\t\t\t\tcurl -fsSL https://raw.githubusercontent.com/curusarn/resh/master/scripts/rawinstall.sh | bash;\n\t\t\t\t_print_ \"RESH installed successfully!\";\n  \t\t\t\t_log_ \"info\" \"RESH installed\";\n  \t\t\telse\n  \t\t\t\t_print_ \"No worries!\";\n\t\t\t\t_log_ \"warn\" \"RESH installation denied\";\n\t\t\tfi\n\t\telse\n\t\t\tcurl -fsSL https://raw.githubusercontent.com/curusarn/resh/master/scripts/rawinstall.sh | bash;\n\t\t\t_print_ \"RESH installed successfully!\";\n  \t\t\t_log_ \"info\" \"RESH installed\";\n\t\tfi\n\telse\n\t\t_print_ \"No worries!\";\n\t\t_log_ \"warn\" \"RESH installation denied\";\n\tfi\nelse\n\t_print_ \"RESH found!\";\n\t_log_ \"info\" \"RESH is already installed on this system\";\nfi\n_end_;\n\n\nChruby\n\nI don’t often work with ruby, but when I do, I am alwasy on the wrong version.\n\n_print_header_ \"Chruby\"; # (https://github.com/postmodern/chruby)\nif [[ ! -d \"/usr/local/share/chruby\" ]]; then\n\t_print_ \"Chruby is not installed on this system and is used in ~/.zshrc.\";\n\tif _confirm_ \"Would you like to install Chruby (Ruby Version Manager)?\"; then\n\t\tlatestChruby=$(curl -s https://api.github.com/repos/postmodern/chruby/releases/latest);\n\t\tvChurby=$(echo \"$latestChruby\" | grep -oP '\"tag_name\": \"\\K[^\"]+');\n\t\turlChurby=$(echo \"$latestChruby\" | grep -oP '\"tarball_url\": \"\\K[^\"]+');\n\n\t\tcurl -L -o chruby-latest.tar.gz \"$urlChurby\" &amp;&gt;/dev/null;\n\t\ttar -xzf chruby-latest.tar.gz;\n\t\trepoChurby=$(tar -tzf chruby-latest.tar.gz | awk 'NR==1 {print $1}');\n\t\tcd \"$repoChurby\";\n\t\tsudo ./scripts/setup.sh;\n\n\t\tcd ..;\n\t\trm -r \"$repoChurby\" chruby-latest.tar.gz;\n\n\t\t_print_ \"Chruby installed successfully!\";\n  \t\t_log_ \"info\" \"Chruby installed\";\n\t\n\telse\n\t\t_print_ \"No worries!\";\n\t\t_log_ \"warn\" \"chruby installation denied\";\n\tfi\nelse\n\t_print_ \"chruby found!\";\n\t_log_ \"info\" \"chruby is already installed on this system\";\nfi\n_end_;\n\n\nChezmoi\n\nTo tie all of these tools together, I have my dotfiles saved and managed with chezmoi. Of course, it doesn’t need to be installed if I need a more simple and vanilla setup. But here we will install it, configure it, and apply the dotfiles to all these environment tools. Here, we will use the info of git and ssh from the beginning of the script. It all comes full circle.\n\nif [[ $(command -v chezmoi) ]]; then\n\t_print_header_ \"Dots and Files\";\n\t_print_ \"Chezmoi has been found on your system\";\n\tif _confirm_ \"Would you like to pull all your dotfiles from your dotfiles repo?\"; then\n\t\tif [[ -z $(ls -A \"$HOME/.local/share/chezmoi\") ]]; then\n\t\t\tchezmoi init --apply git@github.com:$GITHUB_USERNAME/$GITHUB_DOTS_REPO.git;\n\t\t\tchezmoi apply;\n\t\t\t\n\t\t\t_print_ \"Dotfiles applied!\";\n  \t\t\t_log_ \"info\" \"Dotfiles migrated to this machine\";\n\t\telse\n\t\t\t_print_ \"There seems to be an instance of Chezmoi here already. We will not init or apply anything for safety.\"\n\t\t\t_log_ \"error\" \"Existing instance of Chezmoi present\"\n\t\tfi\n\telse\n\t\t_print_ \"No dotfiles will be here!\";\n\t\t_log_ \"warn\" \"Dotfile migration denied\";\n\tfi\n\t_end_;\nfi\n\nif [[ -e \"$HOME/.config/chezmoi/chezmoi.toml\" ]]; then\n\t_print_header_ \"Chezmoi Auto Update Dotfiles\";\n\tif _confirm_ \"Would you like to update your Chezmoi config file to auto commit and push newly applied changes?\"; then\t\t\n\t\tif [[ ! $(grep -q \"^[git]$\" \"$HOME/.config/chezmoi/chezmoi.toml\") ]]; then\n\t\t\techo -e \"\\n[git]\" &gt;&gt; \"$HOME/.config/chezmoi/chezmoi.toml\";\n\t\tfi\n\n\t\tif [[ ! $(__tomlLineExists \"autoCommit = true\" \"[git]\" \"$HOME/.config/chezmoi/chezmoi.toml\") ]]; then\n\t\t\tsed -i \"/^[git]\\$/a autoCommit = true\" \"$HOME/.config/chezmoi/chezmoi.toml\";\n\t\tfi\n\t\n\t\tif [[ ! $(__tomlLineExists \"autoPush = true\" \"[git]\" \"$HOME/.config/chezmoi/chezmoi.toml\") ]]; then\n\t\t\tsed -i \"/^[git]\\$/a autoPush = true\" \"$HOME/.config/chezmoi/chezmoi.toml\";\n\t\tfi\n\n\t\t_print_ \"Chezmoi updated to autoupdate dotfile changes!\";\n\t\t_log_ \"info\" \"Chezmoi auto-update of dotfiles config applied\";\n\telse\n\t\t_print_ \"Make sure to manually apply changes in the future!\";\n\t\t_log_ \"warn\" \"Chezmoi auto-update of dotfiles denied\";\n\tfi\n\t_end_;\nfi\n\n\nHomebrew\n\nYou didn’t think I’d forgotten about homebrew, did you? Of course not. homerew stores its info in a brewfile, which is in my dotfiles repo. Thus, we will how apply this file to install all the pachages I need on MacOS.\n\nif [[ \"$osName\" == \"mac\" ]]; then\n\t_print_header_ \"Homebrew Programs\";\n\tif _confirm_ \"Would you like to install the MacOS predefined Homebrew applications from the Brewfile in your home directory?\"; then\n\t\tbrew bundle install;\n\n\t\t_print_ \"Brewfile taps and casks installed!\";\n  \t\t_log_ \"info\" \"Brewfile items installed on this Mac\";\n\telse\n\t\t_print_ \"It's a clean slate!\";\n  \t\t_log_ \"info\" \"Brewfile not auto-installed on this Mac\";\n  \tfi\n  \t_end_;\nfi\n\n\nCleanup\n\nAnd that’s it! This is my version of the script, but please feel free to copy and adapt it to your own needs. You can find the full version here. Before we termiante, let’s quickly cleanup gum, which we installed only for pretty printing.\n\nif [[ $prettyPrint == 1 ]]; then\n\t_print_ \"Uninstalling gum\"\n\tprettyPrint=0;\n\tif [[ \"$osName\" == \"mac\" ]]; then\n\t\tbrew uninstall gum;\n\telif [[ \"$DISTRO\" == \"Ubuntu\" ]]; then\n\t\tsudo apt-get -y purge gum;\n\t\tsudo rm /etc/apt/sources.list.d/charm.list;\n\t\tsudo rm /etc/apt/keyrings/charm.gpg;\n\tfi\nfi\n\n\nFinally, we will display some helpful reminders to the user before closing.\n\necho -e \"\\n\\u001b[33mRemember to press [PREFIX-I] in Tmux to install the plugins.\\u001b[0m\\n\"\necho -e \"\\n\\u001b[33mRemember to execute :PlugInstall in Vim to install the plugins.\\u001b[0m\\n\"\necho -e \"\\n\\u001b[33mRemember to generate any necessary GPG keys for Git and other applications.\\u001b[0m\\n\"\n\necho -e \"##################################################\\n\"\n\n\nCongrats! How you will never need to manually install your environment again.\n\nConclusion\n\nThe purpose of this post is two fold. First, I needed an excuse to share my micro-obsession for the past week. Second, I wanted to remind both myself and you reading that automation and virtualization is an underutilized power combo. If it doesn’t need to be on bare metal, it’s worth considering a virtural buffer. Especially with the rise fo cloud computing, having your applications be modular and movable is more critical than ever.\n",
      "categories": [],
      "tags": [],
      
      "collection": "posts",
      "url": "/blog/2025-07-27-port-my-env/"
    },{
      "image": {"path":"/assets/img/projects/discord-quotebot-cover.png"},
      "title": "Quotebot",
      "date": "2024-03-02 00:00:00 +0000",
      "description": "My friends say the darnedest things and I aim to capture them all for eternity.\n",
      "content": "\n  I like to Hang Out with Friends\n  The Idea    \n      What’s a Discord Bot?\n      Message Formats\n    \n  \n  Boring Chores    \n      Settings\n      Adding the Bot\n    \n  \n  Main Functions    \n      Quotes\n      Editing        \n          Helper\n          Author\n          Quote\n        \n      \n      Configuration        \n          Prefix\n          Channel\n        \n      \n    \n  \n  Conclusion\n\n\nI like to Hang Out with Friends\n\nI’ll admit it now, I’m not much of a gamer as I use to be. Discord was my home for a time long ago (and maybe it will be soon if their rebrand into the corporate space somehow succeeds), but now I use to remind myself that I need to carve out time for those around me lest I let work consume my waking hours. When I do make time for them, it is a neverending stream of joy, laughter, and the occasional existential crisis. Admist all of this, criminally iconic lines are uttered to the ether, which I find unforgivable. These one-shot lines deserve to be saved reminiscing, a walk down memory lane, or simply future “reference” material. As such, I aimed to create another data-entry front-end for my enjoyment.\n\nAlright alright, I made the basis of this project many many moons ago, but I’ve only recently pushed it to a point where I can be somewhat okay in letting it run amuck in the wild. So if the dates seem wrong, they’re not; I’m just lazy.\n\nThe Idea\n\nSince Discord was the go-to platform, it was only natural that I develop something for the server that I was apart of. I didn’t want anything fancy, just something to get the job done. The bot wasn’t doing the heavy lifting, only the decorating. It should be able limited to a specific channel in a Discord server, and the bot should manage the format of the channel automatically. That is, when a user submits a quote, the submission should not clutter the channel itself. Rather, it should be a beautiful wall of quotes and only quotes. This way, all the quotes will be in one place, easily searchable, and can be referenced at any time.\n\nWhat’s a Discord Bot?\n\nDiscord bots are nothing more than web applications that can communicate with Discord’s API. You can read the full documentation on Discord’s Developer Documentation. Technically, their official term is called Discord Apps. While their feature set is extensive, this bot will only do the basic of basics: listen for messages, parse them, post them, delete them, and store them. There’s no need for real-time updates, interactions, or anything fancy. With that being said, this project will only scratch the surface of what Discord bots can do. If you want to learn more about the possibilities, I recommend checking out Discord.js or Discord.py. While many facor using Javascript, this project will use Python and Discord.py.\n\nMessage Formats\n\nFor many reasons, I’ve chosen the MLA7 Citation Style. Specifically, I wanted the in-text citation style of “Quote” (Author, Year). This gives me all the information I need to filter for the yearly rewind, the ability to see the magnificent creator of the quote, and the said quote itself. Really anything can be in the Quote part of the message, so linting and input validation are a consideration. The Author field will be the Discord handle and the Year should be automatically generated based on when the quote is submitted to the bot.\n\nFor the user input, we want it to be as simple as possible. Thus the user should only need to specify two things: the quote itself and the author of the quote. The bot will then take care of the rest. We need to make sure that the author is a Discord user tag, so the author needs to start with teh @ symbol. The bot will be looking for this while parsing the message. Otherwise, any other character should be valid in the quote, as long as it is betwen two quotation marks.\n\nWe will be looking for straight quotes, so any curly or styled quotes will not be recognized by the bot. Of course, this is a simple fix, but I have to keep my friends humble.\n{.note title=”Types of Quotation Marks”}\n\nOne final bit on the order of information. Becasue we want to make sure that any type of quote can be submitted, we will enforce the fact that the author is always the last item in the message. This way, any amount of whitespace or other characters can be used, and the entore mesage less the final block of text seperated by a whitespace will be the quote.\n\nBoring Chores\n\nFirst things first, you have to get yourself a token for your bot. Login with your Discord account at the Discord’s Developer Portal and create a new application. This will give you a bot token that you can use to authenticate your bot with Discord’s API. You can also set the bot’s name, icon, and description here. Write this down now, as if you loose it, you’ll have a world of heacache trying to re-establish the bot.\n\nAlso, make sure you have a database instance up and running, ready for your bot to connect to, along with a user for the database, lest you give all your applications admin privileges. For this project, I was really into MongoDB at the time, so I used that as my database of choice. You can use any database you want, but you’ll have to modify the code a little.\n\nSettings\n\nFor simplicity, we will have a settings file that will hold the configuration for the bot. The main items required here are a predefined bot prefix, the bot token, the channel ID for the quotes, and the database connection, plus the database and collection items (i.e. the database and table) for MongoDB.\n\n{\n  \"prefix\": \"\",\n  \"BotToken\": \"\",\n  \"ChannelID\": \"\",\n  \"mongoClientID\": \"\",\n  \"databaseName\": \"\",\n  \"collectionName\": \"\"\n}\n\n\nLater, we’ll see that the prefix is not necessary needed given the channelID already sets an exclusive quote zone. In addition, the prefix is simply the starting prefix that can be tuned later.\n\nAdding the Bot\n\nBack on the Discord’s Developer Portal, under Installation, you can generate an OAuth2 URL to add the bot to your server. Make sure you select the correct permissions for the bot, such as Send Messages, Read Message History, and Manage Messages. Once you have the URL, you can add the bot to your server.\n\nMain Functions\n\nThere are three parts to this bot: the main quote handling functions, the database and quote editing functions, and the general bot configuration functions. However, before any of that, we need to load a bot. For this, we will use the Discord.py library to create a bot and manage its functionalities. We already have many of the properties set in the settings file, so we can load those in as well. We will also pymongo to connect to the MongoDB database and manage the quotes. To make developnment easier, let’s also set up logging to keep track of the bot’s activities and have a fallback in case of any async errors.\n\nimport json\nimport logging as log\nimport sys\nfrom datetime import date\nfrom datetime import datetime\nfrom pathlib import Path\n\nimport discord\nimport pymongo\nfrom discord.ext import commands\n\n# Loads Settings\nwith open(\"settings.json\", \"r\") as settingsFile:\n    settings: dict = json.load(settingsFile)\n\n# Logging\nlog.basicConfig(level=log.INFO)\n\n# Format the logs\nlogFormat = log.Formatter(\n    \"%(asctime)s - %(levelname)s - %(filename)s::%(funcName)s - %(message)s\")\nrootLogger = log.getLogger()\n\n# Handle the logs into a file\nlogFile = f\"logs/quotebot-{datetime.now().strftime('%d-%m-%Y-%H-%M-%S')}.log\"\nPath(logFile).touch(exist_ok=True)\nfileLogger = log.FileHandler(logFile)\nfileLogger.setFormatter(logFormat)\nrootLogger.addHandler(fileLogger)\n\n# Handle the logs into the console\nconsoleLogger = log.StreamHandler(sys.stdout)\nconsoleLogger.setFormatter(logFormat)\nrootLogger.addHandler(consoleLogger)\n\n# Set the premissions for the bot\nintents: discord.Intents = discord.Intents.default()\nintents.message_content = True\n\n# Loads Bot\nbot = commands.Bot(command_prefix=settings[\"prefix\"],\n                   intents=intents,\n                   help_command=None)\n\n# Loads db\nmyclient: pymongo.MongoClient = pymongo.MongoClient(settings[\"mongoClientID\"] + settings[\"databaseName\"])\nmydb = myclient.get_default_database()\nmycol = mydb[settings[\"collectionName\"]]\n\n# Set the quote number to the last quote number in the database\nno: int = 1\nfor doc in mycol.find({}, {\"_id\": 1}).sort(\"_id\", -1).limit(1):\n    no: int = doc[\"_id\"] + 1\n\n\nTo run the bot, we can run bot.run(settings[\"BotToken\"]) at the end of the file once all functions have been defined. This will initialize the bot to the Discord servers with the token we’ve been given. If you were to start this now, you should see the bot show as online in your server, but it won’t do anything. Let’s make it do something.\n\nQuotes\n\nTo interact with the bot, we will need to define functions for events that the bot will listen for. Thankfully, our defined bot  object has a built-in decorator bot.event for us to use. For this bot, there are two functions that we will need to overload in this decorator: on_ready and on_message. The first will be called when the bot is ready to start receiving messages, and the second will be called when a message is sent in the server. For now, let’s say that when the bot is up and ready, it’ll simply log it. We’ll also update the global quote number from ealier.\n\n@bot.event\nasync def on_ready():\n  global no\n  log.info(\n      f'{bot.user} is connected and has the db of: {str(str(mydb).split(\" \")[-1:])[2:-3]} with collection: {str(str(mycol).split(\" \")[-1:])[2:-3]}'\n  )\n  log.info(f\"Initalized quote number: {no}\")\n\n\nNow for the fun part in on_message. This function will be called every time a message is sent to the server. It is our job now to see if there is anything we need to do. As I’ve mentioned before, the prefix will not be used as long as the channel is defined. That is true, for quotes. For other functionalities, we need to parse the prefix to redirect the command to the right function. We’ll save this discussion for later. For now, let’s simply use the bot’s built in function to parse it like a command if we see the prefix. Because this function will be called for every message, we also need to check if the message is sent to the correct channel (i.e., the quotes channel). Finally, to prevent a positive feedback loop, we will also ignore messages sent by the bot itself, otherwise we will recurs into infinity.\n\n@bot.event\nasync def on_message(message: discord.Message):\n\n  # Check for command prefixes and process commands\n  prefix = settings[\"prefix\"]\n  if message.content.startswith(prefix):\n    await bot.process_commands(message)\n    return\n\n  global no  # global quote number\n\n  # Check of the message is in the channel we are looking for\n  channelWatch = settings[\"ChannelID\"]\n  if str(message.channel.id) != channelWatch:\n    return\n\n  # Check if the message is from the bot\n  if message.author == bot.user:\n    return\n\n\nNow, let’s make sure that there is only one mention in the message; this will be the author of the quote. If there is more or less than one mention, we will ask the user to retry the quote submission. If there is only one mention, we will extract the author of the quote, as well as the submitter of the quote for the database later on.\n\nauthorList: list = message.mentions\n  if len(authorList) &gt; 1 or len(authorList) == 0:\n    await message.delete()\n    await message.channel.send(\n      f\"Error: Please only specify one author for this quote at this time we found {len(authorList)}: {[user.name for user in authorList]} in quote: {message.content}.\",\n      delete_after=60,\n    )\n    log.warning(\n      f\"{message.author} tried to add a quote with {len(authorList)} authors: {[user.name for user in authorList]} and content: {message.content}\"\n    )\n    return\nquoteAuthor: discord.Member = authorList[0]\nquoteSender: discord.User | discord.Member = message.author\n\n# Get a mentionable string for the author\nauthorMentionString: str = quoteAuthor.mention\n\n\nWith the author sorted, let’s turn our attention to the quote itself. As mentioned earlier, the last item in the message itself will be the author. Everything else will be the quote itself. The reason we didn’t parse the author out of the message content itself is becasue the content does not have the right Discord user slug format. Without it, any @s will have no reference and simply be plain text. Thus, the necessity to extract the author from the mentions. Now, we can simply extract the content minus the last item to form the quote.\n\n# Get the content of the message and make sure the citation is at the end of the message\nquoteContent: str | list = message.content\nquoteContent = quoteContent.split(\" \")\nquote: str = \" \".join(quoteContent[:-1])\nif quoteContent[-1] != authorMentionString:\n  await message.delete()\n  await message.channel.send(\n    f\"Error: Please make sure to mention the author at the end of the quote For example: {quote} @citation.\",\n    delete_after=60,\n  )\n  log.warning(\n    f\"{message.author} tried to add a quote without mentioning the author at the end of the quote: {quote}\"\n  )\n  return\n\n\nFinally, we will add the year to the quote.\n\n# Get's current year for citationå\ntoday: date = date.today()\ntime: datetime | str = datetime.now()\ntime = time.strftime(\"%H:%M:%S\")\nyear: int = today.year\n\n\nA small side step. Discord has some basic * markdown formatting, and we will be utilizing it to format the final quote for the channel. As such, we will need to make sure any quote that already contains * is escaped so as to not mess up the formatting.\n\n# Sanitize the quote to prevent * from messing up the formatting\nsanitizedQuote = quote.replace(\"*\", \"\\\\*\")\n\n\nNow we can construct the full quote message\n\n# Sends formatted message &amp; cleans up\nfullQuote = (str(no) + \": \"\n            '***\"' + sanitizedQuote + '\"' + \".*** `(`\" +\n            authorMentionString + \"`, \" + str(year) + \")`\")\nquote_message = await message.channel.send(fullQuote)\njumpURL: str = quote_message.jump_url\nawait message.delete()\n# Invisible character for double spacing\nawait message.channel.send(\"\\u3164\")\n\n\nTo wrap everything up, we will take the data we’ve gathered and store it into the database and increase the global quote number. The database will include the quote number, the quote itself, the author, the submitter, the time, the date, and the jump URL for the quote message (which was retrieved in the code block above). The jump URL is a link to the message itself, which can be used to reference the quote later on.\n\n# Write to Database\nmycol.insert_one({\n  \"_id\": no,\n  \"quote\": quote,\n  \"author\": str(quoteAuthor),\n  \"sender\": str(quoteSender),\n  \"time\": str(time),\n  \"day\": str(today),\n  \"url\": str(jumpURL),\n})\n\n# print to console\nlog.info(\n  f'Added quote no: {no} to database: \"{quote}\", {quoteAuthor.name} from {quoteSender.name}. `{str(jumpURL)}`'\n)\n\nno += 1\n\n\nWhile I haven’t explicitly mentioned it, you’ll notice that for any error or completion of task, the bot will delete the message sent by the user. This is the cleanup management that I mentioned at the beginning. You’ll see this throughout the bot, ensuring that the task is completed before clearing the message. This way, no data is lost in case of error, and cleanup is very low on priority.\n{.note title=”Message Cleanups”}\n\nEditing\n\nFor editing previous quotes, we will define two options: the quote itself, and the author of a quote. The command format will be &lt;prefix&gt;e author &lt;quote number&gt; &lt;new author&gt; or &lt;prefix&gt;e quote &lt;quote number&gt; &lt;new quote&gt;. Let’s define a main edit function to handle the command call. We will check the format and validity of the command and send the result to the correct editing functions.\n\n# ? Args0 will be option of edit | args1 will be quote to edit\n@bot.command(name=\"e\", help=\"Edits previous quotes in database\")\nasync def edit(ctx, *args):\n  if len(args) == 0:\n    await ctx.message.delete()\n    await ctx.send(\n        \"Error: No arguments supplied. The current available options are: |author|, |quote|.\",\n        delete_after=5,\n    )\n    return\n\n  if args[0] == \"author\":\n    await authorEdit(ctx, mycol, *args)\n    log.info(f\"Author edit: {args[1]}\")\n  elif args[0] == \"quote\":\n    await quoteEdit(ctx, mycol, *args)\n    log.info(f\"Quote edit: {args[1]}\")\n  else:\n    await ctx.message.delete()\n    await ctx.send(\"Error: That is not a current valid editing opiton\",\n                    delete_after=5)\n\n\nHelper\n\nFor the edit commands, we will need to reach into the database to find the quote jump url we want to edit, so we can update the channel’s message. Thus, a simple function to return the quote jump url given the quote number and collection will be useful. Discord.py expects only the jump ID and not the full URL, we will only return that part.\n\n#fetches data for the old message to be edited \ndef orgMsgFind(mycol,idxNo):\n  for entry in mycol.find({\"_id\":int(idxNo)}):\n    return entry['url'].split('/')[-1]\n\nAuthor\n\nTo edit the author, we retrieve the new author information, update the database and channel, and log it. Gathering the new author information is the same as a new quote. Updating the database is also simple enough. Updating the channel message requires fetching the message using the jump URL, replacing the old author with the new author, and then sending the updated message. Finally, as a curtsey, we will delete the edit message to keep the channel clean.\n\nasync def authorEdit(ctx,mycol,*args):\n  if len(args) != 3:\n    await ctx.message.delete()\n    await ctx.send(\"Error: The arguments are incorrect. The format is: \\\"e author [Quote Index No.] [New Author Tag]\", delete_after=5)\n    return\n      \n  #Gets new Author Information\n  newAuthorID = ctx.message.content[ctx.message.content.find('&lt;'):ctx.message.content.find('&gt;')+1]\n  newAuthor = ctx.message.mentions[0]\n      \n  #Updates Database\n  result = mycol.update_one({\"_id\":int(args[1])},{\"$set\":{\"author\":str(newAuthor)}})\n  if result.acknowledged:\n    await ctx.send(f\"Updated the author of quote {str(args[1])} to {str(newAuthor)}\", delete_after=5)\n  else:\n    await ctx.send(\"Error: Failed to update quote.\")\n      \n  #Update Visible Book \n  quoteID = orgMsgFind(mycol,args[1])\n  orgMsg = await ctx.channel.fetch_message(quoteID) \n  oldAuthorID = orgMsg.content[orgMsg.content.find('&lt;'):orgMsg.content.find('&gt;')+1]\n  newMsg = str(orgMsg.content).replace(oldAuthorID,newAuthorID)\n  await orgMsg.edit(content=newMsg)\n              \n  await ctx.message.delete()\n\n\nQuote\n\nUpdating the old quote is very similar to updating the author. The databbase update and jump url fetch is the same. To update the channel message, we will take advantage of the fact that the quote is always between two \" characters. Thus, we simply replace the content between the first and last \" characters with the new quote.\n\nasync def quoteEdit(ctx,mycol,*args):\n  if len(args) != 3:\n    await ctx.message.delete()\n    await ctx.send(\"Error: The arguments are incorrect. The format is: \\\"e author [Quote Index No.] \\\"[New Quote]\\\"\", delete_after=5)\n    return    \n  \n  newQuote = str(args[2])\n\n  result = mycol.update_one({\"_id\":int(args[1])},{\"$set\":{\"quote\":str(newQuote)}})\n  if result.acknowledged:\n    await ctx.send(f\"Updated the quote of quote {str(args[1])} to {str(newQuote)}\", delete_after=5)\n  else:\n    await ctx.send(\"Error: Failed to update quote.\")\n  \n  quoteID = orgMsgFind(mycol,args[1])\n  orgMsg = await ctx.channel.fetch_message(quoteID) \n  quotePOS = [pos for pos, char in enumerate(orgMsg.content) if char == '\"']\n  oldQuote = orgMsg.content[quotePOS[0]+1:quotePOS[1]]\n  newMsg = str(orgMsg.content).replace(oldQuote,newQuote)\n  await orgMsg.edit(content=newMsg)   \n  \n  await ctx.message.delete()\n\n\nConfiguration\n\nThere is little configuration for this simple bot. We will define two configurations that can be changed: the prefix, and the channel ID. It should be noted that because these commands use a prefix, they are not bound to a specific channel and can be called anywhere in the server. In fact, they should be called somewhere other than the quotes channel to ensure everything is clean and tidy.\n\nPrefix\n\nThe prefix can be set to anything. So the command format we will define here is &lt;prefix&gt;p &lt;new prefix&gt;. This will change the prefix for the bot to the new prefix. Of course, let’s also do some bounds checking here to ensure that the command in given correctly. If the command is sent in the quotes channel, we’ll be kind and remove the command message to help with tidyness. Finally, let’s save this change to the settings file so that it persists across bot restarts.\n\n@bot.command(name=\"p\", help=\"Set the prefix of quote\")\nasync def prefixSetting(ctx, *args):\n  if len(args) == 0:\n    await ctx.message.delete()\n    await ctx.send(\"Error: No arguments supplied.\")\n    return\n  elif len(args) != 1:\n    await ctx.message.delete()\n    await ctx.send(\"Error: Please input only one prefix\")\n    return\n\n  if args[0] == \"\":\n    await ctx.message.delete()\n    await ctx.send(\"Error: Please input a valid prefix\")\n    return\n\n  # Keep the quote channel clean\n  if str(ctx.message.channel.id) == settings[\"ChannelID\"]:\n    await ctx.message.delete()\n\n  bot.command_prefix = args[0]\n  await ctx.send(f\"Updated prefix to {args[0]}!\", delete_after=60)\n  log.info(f\"Updated prefix to {args[0]}!\")\n\n  with open(\"settings.json\", \"r+\") as settingsFile:\n    settingsData = json.load(settingsFile)\n    settingsData[\"prefix\"] = str(args[0])\n    settingsFile.seek(0)\n    json.dump(settingsData, settingsFile, indent=4)\n    settingsFile.truncate()\n\n\nChannel\n\nThe channel ID is a little more complex. While the command is still simple, &lt;prefix&gt;c &lt;channel ID&gt;, we will need to extract the tagged channel ID to ensure we have the correct reference. However, once the format is identified, we can simply remove any unnecessary characters as all we are looking for is the channel ID itself. We will do the usual bounds checking, setting files update, and the cleanup as necessary.\n\n@bot.command(name=\"c\", help=\"Change the channel that the quotebot listens in\")\nasync def channelChange(ctx, *args):\n  if len(args) != 1:\n    await ctx.message.delete()\n    await ctx.send(\n      \"Error: please tag only one channel that will be the quote channel.\"\n    )\n\n  if args[0][0] != ctx.message.channel.mention[0]:\n    await ctx.message.delete()\n    await ctx.send(\"Error: Please tag the channel with the # symbol.\")\n    return\n\n  # Get the channel ID from the arg\n  newChannelID = str(args[0][2:-1])\n  settings[\"ChannelID\"] = newChannelID\n\n  with open(\"settings.json\", \"w\") as settingsFile:\n    settingsFile.seek(0)\n    json.dump(settings, settingsFile, indent=4)\n    settingsFile.truncate()\n\n  # Keep the quote channel clean\n  if str(ctx.message.channel.id) == newChannelID:\n    await ctx.message.delete()\n\n  await ctx.send(f\"Updated the listening channel to {args[0]}!\",\n                  delete_after=60)\n  log.info(f\"Updated the listening channel to {args[0]}!\")\n\n\nConclusion\n\nAnd that’s it! A simple record keeper bot for you and your friends! While I’ve ventured less and less onto Discord itself, I still find myself using this bot to capture IRL moments in a swift fashion. It allows me to give a Spotify-wrapped-esque gift to everyone as my obligatory Christmas White Elephant entry. I hope you found some snippet of this project useful as a takeaway for your time spent reading my ramblings. If nothing else, realize this: 90% of software development industry is simply making a front-end for data, from entry to representation and manipulation. So go, find the data that you call home, and make it pretty.\n",
      "categories": [],
      "tags": [],
      
      "collection": "projects",
      "url": "/projects/discord-quotebot/"
    },{
      "image": {"path":"/assets/img/projects/jgrade2-cover.png"},
      "title": "JGrade2",
      "date": "2024-10-13 00:00:00 +0000",
      "description": "An updated plugin for Gradescope users to grade Java submissions like a pro. Updated now for Java 21 and JUnit5 with easy Maven integration.\n",
      "content": "\n  I (kinda) don’t like Java\n  Outdated-ness\n  Enter jGrade2\n  Conclusion\n\n\nI (kinda) don’t like Java\n\nAs a daily driver, I am not a fan of the Java language. Its verbose and clunky syntax is reminiscent of the old days when programming was more about creating the code space than playing in it. As someone who starts a new project every other week, Java’s framework setup eats into those precious few days. However, I do think Java has its place. Its accessibility and standardization make it a well-suited choice for large, legacy-focused systems. Its verbosity is a feature, not a bug- in some cases- and is excellent for “fine-grained control” over a system. Thus, while I discourage programmers from using Java, I heavily encourage computer science students to master it.\n\nAll that is to say, when a professor and colleague came to me for help on this project, I was more than happy to oblige. Not only was it a chance to eliminate more tediousness in this world, but I will never say no to scoring some brownie points with a colleague.\n\nOutdated-ness\n\nThis project is less about the intricacies in Java auto-graders and more about awareness to not only this tool but also the need for versioning, dependency checks, and long-term support. Here’s the issue: A legacy-coding class utilizes JUnit for auto-grading assignments. From unit tests to end-to-end integration checks, this class and the university partner with Gradescope to manage student submissions. (There is also test coverage and mutation testing in the works, but that is a different story.) Origionally written in 2019, @tkutcher wrote the first JGrade to compile Junit’s (v4) output to Gradescope specification. However, as time moved on from the pandemic, so did Junit, and it upgraded to version 5, completely breaking JGrade. While not really a problem if the class locked the version of Junit to v4, they were also updating to Java 21, which was not compatible with Junit4. Stuck between a rock and a hard place, the class implemented a workaround for the time being (i.e., the computing power of the TAs).\n\nEnter jGrade2\n\nI will be frank: this project was more a 2-week exercise of entering and updating a legacy codebase, ironically mirroring the concepts taught in the class this was originally for. Immersing myself into the codebase was easy thanks to @tkutcher’s excellent demonstration of code organization (thank you, Tim!). A glance at the changelog from Junit4 to 5 brought me about 90% of the way there with understanding which methods to update. The other 10% was a matter of understanding the stack trace and creating some test cases to verify sanity. All in all, the main issue came from a rewrite of how Junit5 exposed its test discovery, progress, and results. Since this post won’t be complete without some code, here is a snippet of the rewrite:\n\n// file: `src/main/java/com/github/jgrade2/jgrade2/Grader.java`\n\npublic void runJUnitGradedTests(Class&lt;test&gt; testSuite) {\n  LauncherDiscoveryRequest request = LauncherDiscoveryRequestBuilder.request()\n                                    .selectors(selectClass(testSuite))\n                                    .build();\n\n  GradedTestListener listener = new GradedTestListener();\n\n  LauncherSession session = LauncherFactory.openSession();\n  Launcher launcher = session.getLauncher();\n  launcher.registerTestExecutionListeners(listener);\n  TestPlan testPlan = launcher.discover(request);\n  launcher.execute(testPlan);\n...\n\n\nConclusion\n\nAnd that was pretty much it! The rest of the time was spent creating a new Github organization to host the update in, giving proper credit to @tkutcher, rewriting the examples, establishing a CD/CI pipeline, and registering it onto Maven Central for easy use! Please feel free to check it out and implement it in your classroom workflow. It’s usage is the same as the origional JGrade, with a new dependency import if you use Maven. If you’re too lazy to check out the repo, you can add it to your project with the following addition to your pom.xml:\n\n&lt;dependency&gt;\n  &lt;groupId&gt;io.github.jgrade2&lt;/groupId&gt;\n  &lt;artifactId&gt;jgrade2&lt;/artifactId&gt;\n  &lt;version&gt;${jGrade2.version}&lt;/version&gt;\n&lt;/dependency&gt;\n\n\nThanks for reading this short project! I hope you’re able to get some use out of this new plugin!\n",
      "categories": [],
      "tags": [],
      
      "collection": "projects",
      "url": "/projects/jgrade2/"
    },{
      "image": {"path":"/assets/img/projects/loget-cover.png"},
      "title": "Loget Tracker",
      "date": "2024-10-13 00:00:00 +0000",
      "description": "I fell for Japan’s tourist trap and now I’m spreading it to you.\n",
      "content": "\n  Japan’s Department of Tourism Got Me\n  The Scraper    \n      The Data        \n          Card ID\n          Card Image\n          Card Name\n          Spot Map Link\n          LoGet Website Link\n          Spot Website Link\n        \n      \n      The Process\n    \n  \n  The Website    \n      Overview\n      The Welcome Page\n      The Tracker Page\n    \n  \n  Conclusion\n\n\nJapan’s Department of Tourism Got Me\n\nI recently visited Japan to help out the IDS Department at OsakaU with their interdisciplinary project on teeth segmentation and analysis (that’s a story for another day). Along the way, I found out about Japan’s LoGet Cards, a tourist attraction feeding on the same primal isnticts as trading card games. While I never really got into Pokemon myself, I was immediently hooked for both its fun, ARG style goals while also acting as a guide for my expliration of this small island nation. I was a little sad when I realized there were a few limited edition cards that I could not aquire, but that was all apart of the game.\n\nYou can imagine my surprize when I collected about a dozen of these cards and wanted to start keping track of which ones I had, that there was no official, or even unofficial, site to record your progress. I know I know, it’s very maximalist of me, and yes, I like games that are simply glorifiwed spreadsheets. But nonetheless, I needed to know. So with the remaining motivation I had after I returned home, I took a weekend to code this up as one final parting gift to myself, and as a promise to return soon.\n\nThe Scraper\n\nAs with all good proejcts, we start off with something other than the main feature. In this case, I needed to build and update the database of cards so I have something to work with. While I could’ve just simply started with some random data, I would’ve needed to make this feature in the future anyways, so I might as well get it out of the way now.\n\nThe Data\n\nThe main items that we want to collect are:\n\n\n  Card ID\n  Card Name\n  Card Image\n  Spot Map Link\n  LoGet Website Link\n  Spot Website Link\n\n\nAll of these items can be found by parsing the HTML of the LoGet website, and extracting their well defined URL slugs and DOM structure.\n\nCard ID\n\nFor the card ID, we take a look at the LoGet website’s main index page of all the cards. Each item is stored in an &lt;article&gt; element with an href to the card’s page. Thus, using bs4, we can easily find all &lt;article&gt; elements and extract the data we need. Each cards’ page link is of the form ...list.aspx?card={cardId}. Thus, we search for this form and extract the card ID from the URL.\n\nfor article in soup.find_all(\"article\"):\n  for a in article.find_all(\"a\"):\n    assert a[\"href\"].startswith(\"list.aspx?card=\"), f\"Unexpected URL format in finding card Ids: {a['href']}\"\n    u = urlparse(a[\"href\"])[4].split(\"=\")\n    cardIds.append(u[1])\n\n\nCard Image\n\nThe card image also appears on the index page, so we can extract it here as well. Each image is stored in an &lt;img&gt; element with a src attribute that contains the relative path to the image in the form ./img/cards/. As such, we extract this path and can use it to directly access the image for our own website use. We do this for each &lt;article&gt; element that we found earlier. We will use this path to construct the full URL to the image.\n\nfor article in soup.find_all(\"article\"):\n  ...\n  for img in article.find_all(\"img\"):\n    assert img[\"src\"].startswith(\"./img/cards/\"), f\"Unexpected URL format in finding card Ids: {img['src']}\"\n    v = img[\"src\"].split(\"/\")\n    cardImg.append(v[-1])\n\n\nCard Name\n\nThis is a good time to talk about the URL constructor. LoGet is very standardized in their URl slugs. With the .aspx extension, we can deduce that LoGet is using ASP.NET. As such, given the card ID, we can construct the URL to the card’s page, plus a few more crucial pages.\n\nif typ == \"card\":\n  return f\"https://loget-card.jp/list.aspx?card={inputPart}\"\nelif typ == \"map\":\n  return f\"https://loget-card.jp/list_map.aspx?card={inputPart}\"\nelif typ == \"img\":\n  return f\"https://loget-card.jp/img/cards/{inputPart}\"\nelse:\n  raise ValueError(f\"Unexpected type of URL to reconstruct: {typ}\")\n\n\nI bring this up now as the card URL is very useful for extracting the card name. Each card’s page has the card’s name as the first thing in the &lt;h1&gt; element. Thus, we can simply, for each card, go to its page, and extract the name from the &lt;h1&gt; element.\n\nresponse = r.get(cardURL)\n    soup = BeautifulSoup(response.content, \"html.parser\")\n    s = soup.find_all(\"section\", class_=\"listA\")\n\n    assert len(s) == 1, f\"Unexpected number of sections in finding card name: {len(s)}\"\n\n    head = s[0].find_all(\"h1\")\n\n    assert len(head) == 1, f\"Unexpected number of h1 tags in finding card name: {len(head)}\"\n\n    return head[0].text\n\n\nAt this point you might be thinking, “Wow, that’s a lot of requests to make for each card, its tedious and intensive for each refresh.” You are correct, but we will minimize the calls later on in the main function. For now, let’s keep extracting data.\n\nSpot Map Link\n\nThis is simply the URL to the card’s spot map, which has already been defined in the URL constructor above. We can retrieve the map link by calling the URL contructor with the card ID and the map type.\n\nLoGet Website Link\n\nThis is simply the URL to the card’s page, which has already been defined in the URL constructor above. We can retrieve the LoGet website link by calling the URL contructor with the card ID and the card type.\n\nSpot Website Link\n\nThe Spot Website Link is found at the footer of each card’s page. We simply extract the footer text, find the link that opens a new tab, and extract the URL from it. Nothing too complicated once the structure has been determined. This links to an external website so we assume here that each card page is structured the same as there is no way to validate the link we’ve extracted.\n\nresponse = r.get(cardURL)\nsoup = BeautifulSoup(response.content, \"html.parser\")\ns = soup.find_all(\"section\", class_=\"listA\")\n\nassert len(s) == 1, f\"Unexpected number of sections in finding card name: {len(s)}\"\n\nspot = s[0].find_all(\"div\", class_=\"text_footer\")\n\nassert (len(spot) == 1), f\"Unexpected number of a tags in finding card name: {len(spot)}\"\n\nlink = spot[0].find_all(\"a\", target=\"_blank\")\n\nassert (len(link) == 1), f\"Unexpected number of a links in finding card name: {len(link)}\"\n\nreturn link[0][\"href\"]\n\n\nThe Process\n\nNow that we have all the data scraping methods defined, we can put them together. For now, we ignore any logging function that is available to the scraper. This scraper should automatically update our database with the card infos that we’ve collected. As this database uses PostgreSQL, we will use the psycopg2 library to connect to the database and insert the data. We grab a cursor, and for each card already in the database, we will bring it into the scraper for duplicate checking. Of course, this can be optimized by offloading the data check to the database itself. However, as I was developing it on a shotty internet connection, I wanted to minimize the number of requests made to the database. This is a low hanging improvement for the future that I will never get to.\n\nconn = psycopg2.connect(service=DBSERVICE)\ncur = conn.cursor()\ncur.execute('SELECT \"Id\" FROM tracker_logetcards;')\nexistingCardIds = [str(x[0]) for x in cur.fetchall()]\n\n\nNext, we send a request for the LoGet index page and parse it with bs4. Now, we take our above methods and extract some basic info about each card on the page to do the duplicate check.\n\nresponse = requests.get(CARDLISTURL)\nsoup = BeautifulSoup(response.content, \"html.parser\")\ncardIds, cardImgs = findCards(soup)\n\n\nFinally, for each card that we’ve found on the page, we check if it already exists in the database. If it does not, we use the above data methods to extract the required information, add it to the database, and commit the changes.\n\nfor cardId, cardImg in zip(cardIds, cardImgs):\n  if cardId in existingCardIds:\n      continue\n\n  cardURL = logetURLReconstructor(cardId, \"card\")\n  mapURL = logetURLReconstructor(cardId, \"map\")\n  imgURL = logetURLReconstructor(cardImg, \"img\")\n\n  name = findCardName(cardURL)\n  spotLink = findCardSpotLink(cardURL)\n\n  cur.execute(\n      'INSERT INTO tracker_logetcards (\"Id\", \"Name\", \"Img\", \"SpotmapLink\", \"LoGetURL\", \"SpotWebsiteLink\") VALUES (%s, %s, %s, %s, %s, %s);',\n      (cardId, name, imgURL, mapURL, cardURL, spotLink),\n  )\n  conn.commit()\n\n\nAs cleanup, we will close the cursor and connection to the database.\n\ncur.close()\nconn.close()\n\n\nNow we’re done and we have a database of all the LoGet cards that we can use to build our website. We can simply run this scraper whenever we want to update the database with new cards, or to check for any changes in the existing cards. It can also be attached to a cron job to run periodically.\n\nThe Website\n\nNow for the main event. The website is built using Django. I will spare you all the details and give you a highlight of all the main features. An indepth exploration of the code can be found at the Github Repo.\n\nOverview\n\nThis project uses the built in Django admin interface to manage the users and the database. As such, it is not the prettiest thing in the world. However, it’ll do for now. There really are only a few pages that make up this website. Any other slugs are used for hooks and API calls.\n\npath(\"\", views.index, name=\"index\"),\npath(\"tracker/\", views.tracker, name=\"tracker\"),\npath(\"settings/\", views.settings, name=\"settings\"),\npath(\"login/\", views.loginView, name=\"login\"),\npath(\"signup/\", views.signupView, name=\"signup\"),\n\n\nWe’ll skip over most of these pages, as they are as standard as can be. We will focus on the first two: the index page and the tracker page.\n\nThe Welcome Page\n\nI wanted the main page to look somewhat welcoming, so I decided to add a little animation of the cards flying by in the background for flavor. The index view takes in only three context items: the list of random cards, the signup redirect view, and the login redirect view. The random cards are retrieved from the database of cards. If the user has already been logged-in, we will redirect them to the tracker page automatically.\n\nif request.user.is_authenticated:\n  return redirect(\"tracker:tracker\")\n\ncardsImgs = LoGetCards.objects.values_list(\"Img\", flat=True)\nrandImgs = rand.sample(list(cardsImgs), 6)\n\ncontext = {\n  \"imgs\": randImgs,\n  \"loginview\": \"tracker:login\",\n  \"signupview\": \"tracker:signup\",\n}\n\nreturn render(request, \"tracker/index.html\", context)\n\n\nI won’t show or explain every part of the static and template items, but here are the main points. Besides the buttons to login and signup, this front page only has a bunch of image &lt;div&gt;s to contain the card images that will scroll past behind. If we somehow cannot access the database or the backend returns an error, we degrade gracefully and simply use the first six card IDs as the cards for the background animation.\n\n&lt;div class=\"background\"&gt;\n  {% if imgs %}\n    {% for img in imgs %}\n      &lt;div class=\"card\"&gt;&lt;img src=\"{{ img }}\"/&gt;&lt;/div&gt;\n    {% endfor %}\n  {% else %}\n    &lt;div class=\"card\"&gt;&lt;img src=\"https://loget-card.jp/img/card/001.png\"/&gt;&lt;/div&gt;\n    &lt;div class=\"card\"&gt;&lt;img src=\"https://loget-card.jp/img/card/002.png\"/&gt;&lt;/div&gt;\n    &lt;div class=\"card\"&gt;&lt;img src=\"https://loget-card.jp/img/card/003.png\"/&gt;&lt;/div&gt;\n    &lt;div class=\"card\"&gt;&lt;img src=\"https://loget-card.jp/img/card/004.png\"/&gt;&lt;/div&gt;\n    &lt;div class=\"card\"&gt;&lt;img src=\"https://loget-card.jp/img/card/005.png\"/&gt;&lt;/div&gt;\n    &lt;div class=\"card\"&gt;&lt;img src=\"https://loget-card.jp/img/card/006.png\"/&gt;&lt;/div&gt;\n  {% endif %}\n&lt;/div&gt;\n\n\nNow for the fun part. I want the cards to have a random duration of scrolling past the screen. For that, we will use Javascript to generate random durations for each &lt;div&gt; that has the .card class. This was, we can continue the annimation in CSS.\n\ndocument.addEventListener(\"DOMContentLoaded\", () =&gt; {\n  const cards = document.querySelectorAll(\".card\");\n\n  cards.forEach((card, _) =&gt; {\n    const randomDuration = Math.random() * 25 + 5; // between 5 and 30 seconds\n    card.style.animationDuration = `${randomDuration}s`;\n  });\n});\n\n\nAs for the CSS, I want to displace the cards so that they’ll scroll past randomly throuhgout the width of the screen. For this, we will displace each card and use the @keyframe property in CSS. On top of that, I also want the main logo to move a little so its not so static and lifeless. Finally, let’s make it fancy and add an effect to the buttons when you hover over them.\n\n.background {\n    position: absolute;\n    top: 0;\n    left: 0;\n    width: 100%;\n    height: 100%;\n    z-index: -1;\n    overflow: hidden;\n}\n\n.card {\n    position: absolute;\n    width: 100px;\n    height: 150px;\n    background: rgba(255, 255, 255, 0.2);\n    border-radius: 10px;\n    animation: move 20s linear infinite;\n}\n\n.card:nth-child(1) {\n    left: 20%;\n    animation-duration: 15s;\n}\n\n.card:nth-child(2) {\n    left: 40%;\n    animation-duration: 25s;\n}\n\n.card:nth-child(3) {\n    left: 60%;\n    animation-duration: 20s;\n}\n\n.card:nth-child(4) {\n    left: 80%;\n    animation-duration: 30s;\n}\n\n.card:nth-child(5) {\n    left: 10%;\n    animation-duration: 10s;\n}\n\n.card:nth-child(6) {\n    left: 0%;\n    animation-duration: 5s;\n}\n\n@keyframes move {\n    0% {\n        transform: translateY(100vh);\n    }\n    100% {\n        transform: translateY(-100vh);\n    }\n}\n\n.logo {\n    animation: float 3s ease-in-out infinite;\n}\n\n.logo img {\n  width: 500px;\n  display: flex;\n  justify-content: center;\n  margin-bottom: 10px;\n}\n\n\n@keyframes float {\n    0% {\n        transform: translateY(0);\n    }\n    50% {\n        transform: translateY(-20px);\n    }\n    100% {\n        transform: translateY(0);\n    }\n}\n\n.signup:hover, .login:hover {\n  color: #333;\n  background-color: white;\n  border: 2px solid;\n}\n\n\nThe Tracker Page\n\nThe tracker view is simply a grid of the cards. Through the models, we grab the collected cards of the user and the full list of cards data. We also need some basic user account data and pass them all as the context to the template. Here, I chose to handle the processing of collected cards in the template itself.\n\n@login_required\n\nuser = request.user\nuserCards = LoGetUsers.objects.get(user=user).CardsColleted[\"collected\"]\nuserCardIds = [int(card) for card in userCards]\n\ncards = LoGetCards.objects.all()\ncontext = {\n    \"cards\": cards,\n    \"collected\": userCardIds,\n    \"username\": request.user.username,\n    \"logoutview\": \"tracker:logout\",\n    \"userview\": \"tracker:settings\",\n}\nreturn render(request, \"tracker/tracker.html\", context)\n\n\nSpeaking of the template, the tracker page is even more simple than the index page. Besides the helper functions like username, settings, etc., we simply loop through each card in the context, display it on the page, and add an overlay for checking and unchecking a card from the user’s collection.\n\n{% if cards %}\n  &lt;div class=\"container\"&gt;\n    {% for card in cards %}\n      &lt;div id=\"{{ card.Id }}\" class=\"{% if card.Id in collected %} card collected {% else %} card {% endif %}\"&gt;\n        &lt;a href=\"{{ card.LoGetURL }}\" target=\"_blank\"&gt;\n          &lt;img src=\"{{ card.Img }}\" alt=\"{{ card.Name }}\"/&gt;\n        &lt;/a&gt;\n        &lt;div class=\"overlay\"&gt;\n          &lt;button class=\"greenCheck\" data-id=\"{{ card.Id }}\"&gt;✔&lt;/button&gt;\n          &lt;button class=\"redX\" data-id=\"{{ card.Id }}\"&gt;✖&lt;/button&gt;\n        &lt;/div&gt;\n      &lt;/div&gt;\n    {% endfor %}\n  &lt;/div&gt;\n{% endif %}\n\n\nThe javascript simple handles the click events for the buttons and the communication with the backend. As such, I won’t be showing it here. The CSS is much more fun as a few things needed to happen. I needed all non-collected cards to be greyed out, but still have them highlighted when hovered over. Because there is padding between each card, the overlay must follow the shape of the card. The buttons mus talso show changed when hovered over, independently of the card itself. Finally, we need to add some more styling to make everything easy on the eyes.\n\n.container {\n  display: grid;\n  grid-template-columns: repeat(auto-fill, minmax(200px, 1fr));\n  gap: 16px;\n  padding: 16px;\n}\n\n.card {\n  position: relative;\n  opacity: 25%;\n  overflow: hidden\n}\n\n.card:hover {\n  opacity: 100%;\n}\n\n.collected {\n  opacity: 100%;\n}\n\n.container img {\n  width: 100%;\n  height: auto;\n  display: block;\n  border-radius: 8px;\n  box-shadow: 0 4px 8px rgba(0, 0, 0, 0.15);\n}\n\n.bar {\n  display: flex;\n  justify-content: center;\n  padding: 15px;\n  top: 0;\n  width: 100%;\n  box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);\n}\n\n.btn {\n  background-color: #202c70;\n  color: white;\n  border: none;\n  padding: 10px 20px;\n  margin-left: 10px;\n  font-size: 1rem;\n  border-radius: 5px;\n  cursor: pointer;\n  transition: background-color 0.3s ease;\n}\n\n.btn:hover {\n  background-color: #45a049;\n}\n\n.btn:focus {\n  outline: none;\n}\n\n.overlay {\n  position: absolute;\n  top: 0;\n  left: 0;\n  width: 100%;\n  height: 100%;\n  display: flex;\n  justify-content: center;\n  align-items: center;\n  background-color: rgba(0, 0, 0, 0.5);\n  opacity: 0;\n  transition: opacity 0.3s ease;\n}\n\n.overlay button {\n  background-color: white;\n  border: none;\n  padding: 10px;\n  margin: 5px;\n  cursor: pointer;\n  font-size: 20px;\n}\n\n.overlay button.greenCheck {\n  color: green;\n}\n\n.overlay button.redX {\n  color: red;\n}\n\n.card:hover .overlay {\n  opacity: 1;\n}\n\n\nConclusion\n\nThat’s about it. A simple, over-explained project as my tribute to the amazing time I’ve had in Japan. I hope you take this as in inspiration that if something’s missing in your life, you can always build it yourself. Take this as a caution too. I could’ve easily found a simpler way to manage my tracking, this is a pretty frontend to a database afterall, and saved mysef the hours I’ve worked on it. Never forget the cost of convenience. Nevertheless, I’ve had fun. It’s always a pleasure to build something for a small group over a mass audience, even if that small group is just me.\n\nP.S. Can you still try the demo online? Nope. I recieved a nicely worded email kindly requesting me to remove the demo, which I have done. You are still free to tinker with and try out a locally hosted version of the site.\n",
      "categories": [],
      "tags": [],
      
      "collection": "projects",
      "url": "/projects/loget-tracker/"
    },{
      "image": {"path":"/assets/img/projects/myabc-cover.png"},
      "title": "Meshy: A Background that is Cool (MyABC)",
      "date": "2025-02-27 00:00:00 +0000",
      "description": "When creating this website, I wanted a cool cover to greet visitors. Here is what I came up with.\n",
      "content": "\n  Upgrades, Upgrades, Upgrades\n  The Name’s Meshy\n  Starting with Hot HTML and Calm CSS\n  Now for the Fun Part    \n      The Basics\n      Making Triangles\n      Putting Them onto the Screen\n      Less Dense than a DNN\n      Making Them Groove\n      It’s Dynamic Time\n    \n  \n  Conclusion\n\n\nUpgrades, Upgrades, Upgrades\n\nI am a homebrewer myself, and through my days, I’ve had many a home server setups. I used to have an old Wordpress blog under the domain blog.hellodadiam.world. Don’t ask me why; I was in middle school.\n\nRecently, I wanted to revamp all my old projects and microservices into something new and better. Like many starting out in home servers, my old station was a Dell Optiplex. Specifically, it was a i5-2500 Optiplex 990 from eBay that I acquired for less than $100. It served me well for many years as a tinkering machine to learn about the world of SysAdmin.\n\nNow that I am migrating to a better, custom-built server setup that can handle more traffic and computing, it is time to formalize my presence on the web. I was lucky enough to buy this domain to put everything public under. But, as I was searching for hosting options for my permanent website, I was appalled by the monthly prices I needed to pay. Hell, I am an engineer; there must be a better way than this cash-grab of a market for those less technical.\n\nOf course, I could’ve always hosted it on my server. However, I was tired of Wordpress and its lack of interesting themes or starting points. Besides, my server cannot guarantee a 99.99999999% uptime since, well, it’s at home. I wasn’t about to go all raw web application creating either; I can do some full stack dev, but I’m not a full-time web developer. (Oh, who am I kidding, I’m just lazy.) Ultimately, I settled for hosting a static website on Github Pages. I mean, I’m not trying to sell anything or give users an application. I just want a place to show my thoughts and projects.\n\nI think it’s great to learn Jekyll or another static site builder. Unless you need the interactivity, static sites are customizable enough for many use cases. Besides, you can host them for free on Github Pages without needing to pay for a VPS solution (which is a win in this day and age). With all that being said, I still wanted something interesting to greet my visitors, something to stimulate their interest besides still colors and shapes.\n\nThe Name’s Meshy\n\nI call it Meshy for absolutely no reason at all. I wanted an interesting title for this project, and transparent interactive triangle mesh background didn’t roll off the tongue (this isn’t a research paper, after all). Don’t mind the title, it’s more for me than you.\n\nI won’t go into the process of me customizing my entire site, modifying my base theme, or making any other changes tailored to my preference. Everything shown here will work standalone, and it will be up to you to integrate it wherever you want.\n\nYou already know what it looks like since it’s on my website. For completeness, here’s the initial concept: I like those websites with elements that move with the mouse. Because I find the dense neural networks super cool (since I research them), I want to create a mesh that looks like a neural network and is attracted to the mouse. Below are some inspiration images that I started with:\n\n\n\nA dense neural network structure presented as Figure 8.1 in Supervised Machine Learning For Text Analysis in R.\n\n\n\nPhoto by Resource Database on Unsplash.\n\n\n\nPhoto by John Cameron on Unsplash\n\nStarting with Hot HTML and Calm CSS\n\nThe title says it all. The HTML is simply a canvas element, and the CSS helps make the canvas element fill the entire screen. The z-index ensures that it is always the background of any page. This will give us something to work with when we get into the fun part.\n\n&lt;canvas id=\"meshy\"&gt;&lt;/canvas&gt;\n\n\n#meshy {\n    position: fixed;\n    top: 0;\n    left: 0;\n    width: 100%;\n    height: 100%;\n    z-index: -1;\n    overflow: hidden;\n    display: block;\n    background-color: black;\n}\n\n\nNow for the Fun Part\n\nSince we are building a static site, I cannot use any imports or modules to help me with my task; it will be completely native Javascript (my CS professors are rolling in their office hours right about now). That means I have to do math :fearful:.\n\nThe Basics\n\nWe will first get the canvas and the context (2d in this case, unless you want to dive deep).\n\nconst canvas = document.getElementById(\"meshy\");\nconst ctx = canvas.getContext(\"2d\");\n\ncanvas.width = window.innerWidth;\ncanvas.height = window.innerHeight;\n\n\nMaking Triangles\n\nWe will need an array of vertices to create our triangles. I want these triangles to be randomized across the screen. They should also be moving, so we must give them some speed. Let’s define an initial move speed.\n\nTo make these shapes look more dynamic and “alive”, I will vary the opacity of each point, making sure that their opacity does not go below 50%. Let’s write this all out.\n\nlet points = [];\nconst MOVE_SPEED = 0.1;\n\nfunction createPoints(count) {\n    points = [];\n    for (let i = 0; i &lt; count; i++) {\n        points.push({\n            x: Math.random() * canvas.width,\n            y: Math.random() * canvas.height,\n            vx: (Math.random() - 0.5) * MOVE_SPEED,\n            vy: (Math.random() - 0.5) * MOVE_SPEED,\n            opacity: Math.random() * 0.5 + 0.5,\n        });\n    }\n}\n\n\nYou will notice that I added a count argument. This is so that I can adjust the number of triangles on the screen dynamically, so we don’t have to set a magic number in the function. Let’s start with a reasonable 88 points for good luck and run the function.\n\nconst MAX_NUM_POINTS = 88;\n\ncreatePoints(MAX_NUM_POINTS);\n\n\nFinally, let’s turn them into triangles by adding edges to them. The math here is the same as you’ve learned in geometry class. For each pair of points, we’ll define an edge between them.\n\nfunction createEdges() {\n    edges = [];\n    for (let i = 0; i &lt; points.length; i++) {\n        for (let j = i + 1; j &lt; points.length; j++) {\n            edges.push([points[i], points[j]]);\n        }\n    }\n}\n\ncreateEdges();\n\n\n\n\nThe screen we see up until now.\n\nIt’s black…well of course it is! We haven’t done anything with it yet! Let’s keep going.\n\nPutting Them onto the Screen\n\nDrawing them onto the screen isn’t too hard. We want to make sure that the canvas context is starting from a clean slate. We will also set the stroke color, fill color, and line width to be drawn.\n\nconst LINE_STROKE_COLOR = \"rgba(255, 255, 255, 0.5)\";\nconst LINE_STROKE_WIDTH = 0.8;\nconst POINT_FILL_COLOR = \"rgba(255, 255, 255, ${p.opacity})\";\n\nfunction drawMesh() {\n    ctx.clearRect(0, 0, canvas.width, canvas.height);\n\n    ctx.strokeStyle = LINE_STROKE_COLOR;\n    ctx.lineWidth = LINE_STROKE_WIDTH;\n\n    // Draw all edges\n    edges.forEach(([p1, p2]) =&gt; {\n        ctx.beginPath();\n        ctx.moveTo(p1.x, p1.y);\n        ctx.lineTo(p2.x, p2.y);\n        ctx.closePath();\n        ctx.stroke();\n    });\n\n    // Draw points\n    points.forEach(p =&gt; {\n        ctx.beginPath();\n        ctx.arc(p.x, p.y, 2, 0, Math.PI * 2);\n        ctx.fillStyle = POINT_FILL_COLOR;\n        ctx.fill();\n    });\n}\n\ndrawMesh();\n\n\n\n\nThe screen we see up until now.\n\nOh my lord, that’s a dense neural network alright. But while a true DNN is a black box, we don’t want this background to be one.\n\nLess Dense than a DNN\n\nThe problem right now is that each point is being drawn to another point, even if they are across the screen. That makes the triangles overlap and cross over each other. We want to limit the distance the edges can travel between points. This requires updating the createEdges function to check for the distance between points. Since I haven’t used Latex in this post yet, here is the distance formula in case anyone has forgotten it.\n\n$$\n\\begin{aligned}\n    \\sqrt{x^2 + y^2}\n\\end{aligned}\n$$\n\nWe’ll find the distance between the two points and calculate its distance. If the distance exceeds some max, we will not add an edge. For my personal preference, I set this max distance to 150.\n\nconst MAX_EDGE_DISTANCE = 150;\n\nfunction createEdges() {\n    edges = [];\n    for (let i = 0; i &lt; points.length; i++) {\n        for (let j = i + 1; j &lt; points.length; j++) {\n            const dx = points[i].x - points[j].x;\n            const dy = points[i].y - points[j].y;\n            const distance = Math.sqrt(dx * dx + dy * dy);\n\n            if (distance &lt; MAX_EDGE_DISTANCE) {\n                edges.push([points[i], points[j]]);\n            }\n        }\n    }\n}\n\n\n\n\nThe screen we see up until now.\n\nThat looks much better. Every time the page reloads, there will be a random set of triangles. This seems much more manageable and less overwhelming.\n\nMaking Them Groove\n\nHere is where those initial point velocities come in. Instead of having these points slow down or speed up, I want them to fade in and out. That way, we can reuse the opacity setting instead of calculating more speed.\n\nTo move the points, we update their position based on their velocities. If they hit the edge of the screen, we reverse their trajectory so they never leave the window.\n\nFinally, we will fade their opacity over a predefined rate. Once they are gone, I want a new point to spawn. To save on memory and complexity, I can reuse the disappeared point’s object. I’ll recreate the point at a random place and set their random opacity again. The final function looks something like this:\n\nconst POINT_FADE_SPEED = 0.001;\n\nfunction updatePoints() {\n    points.forEach(p =&gt; {\n        p.x += p.vx;\n        p.y += p.vy;\n\n        // Bounce off walls\n        if \\(p.x &lt; 0 \\|| p.x &gt; canvas.width) p.vx \\*= -1;\n        if \\(p.y &lt; 0 \\|| p.y &gt; canvas.height) p.vy \\*= -1;\n\n        // Fade effect\n        p.opacity -= POINT_FADE_SPEED;\n        if (p.opacity &lt;= 0) {\n            p.x = Math.random() * canvas.width;\n            p.y = Math.random() * canvas.height;\n            p.opacity = Math.random() * 0.5 + 0.5;\n        }\n    });\n}\n\n\nWe will wrap these functions into an animation loop to see how they look. Since we only want to create the points once, createPoints will not be a part of this loop.\n\nfunction animate() {\n    createEdges();\n    drawMesh();\n    updatePoints();\n    requestAnimationFrame(animate);\n}\n\nanimate();\n\n\n\n\nThe screen we see up until now.\n\nWe’re 90% of the way there! We have one more feature to add, but before that, let’s add a quick listener so that the animation will restart whenever the window size is changed. That way, the window will never crop or squish the animation.\n\nwindow.addEventListener(\"resize\", () =&gt; {\n    canvas.width = window.innerWidth;\n    canvas.height = window.innerHeight;\n    createPoints(MAX_NUM_POINTS);\n});\n\n\nIt’s Dynamic Time\n\nWhat I want is for the mouse to influence the movement of the points. Specifically, when the mouse is near a cluster of points, it should be attracted to it. We first start by getting the position of the mouse on the screen. We will also add a check to set the position back to null if the mouse ever leaves the screen.\n\nlet mouse = { x: null, y: null };\ncanvas.addEventListener(\"mousemove\", (event) =&gt; {\n    mouse.x = event.clientX;\n    mouse.y = event.clientY; \n});\n\ncanvas.addEventListener(\"mouseleave\", () =&gt; {\n    mouse.x = null;\n    mouse.y = null;\n});\n\n\nFor each point, we want to find the relative path to the mouse. We will use our handy dandy distance formula again to calculate a radius around the mouse for its influence on the points. When it is in this radius, we want to gradually pull the points toward the mouse every frame. If the point is outside of this radius, then we want to slow the point back down to its original move speed.\n\nconst MOUSE_INFLUENCE_RADIUS = 100;\n\n\nfunction applyMouseInfluence() {\n    points.forEach(p =&gt; {\n        let dx = mouse.x - p.x;\n        let dy = mouse.y - p.y;\n        let distance = Math.sqrt(dx * dx + dy * dy);\n\n        if (distance &lt; MOUSE_INFLUENCE_RADIUS) {\n            p.vx += dx * 0.001;\n            p.vy += dy * 0.001;\n        } else {\n            if (Math.abs(p.vx) &gt; POINT_MOVE_SPEED) {\n                p.vx *= 0.999;\n            } else {\n                p.vx = (p.vx &lt; 0 ? -POINT_MOVE_SPEED : POINT_MOVE_SPEED);\n            }\n\n            if (Math.abs(p.vy) &gt; POINT_MOVE_SPEED) {\n                p.vy *= 0.999;\n            } else {\n                p.vy = (p.vy &lt; 0 ? -POINT_MOVE_SPEED : POINT_MOVE_SPEED);\n            }\n        }\n    });\n}\n\n\nOne major problem I see right now is that if the mouse stays still in one place, the points will bounce back and forth around the mouse forever. This is annoying. We will add a movement threshold so that if the mouse stops moving for a while, we will have its influence stop. We define the last mouse movement time and update it whenever it moves. The updated functions look something like this.\n\nconst MOUSE_IDLE_THRESHOLD = 1000;\n\nlet mouseMoveTime = Date.now();\ncanvas.addEventListener(\"mousemove\", (event) =&gt; {\n    ...\n    lastMoveTime = Date.now();\n});\n\nlet timeSinceLastMove = Date.now() - mouseMoveTime;\nfunction applyMouseInfluence() {\n    timeSinceLastMove = Date.now() - mouseMoveTime;\n\n    points.forEach(p =&gt; {\n        let dx = mouse.x - p.x;\n        let dy = mouse.y - p.y;\n        let distance = Math.sqrt(dx * dx + dy * dy);\n\n        if (distance &lt; MOUSE_INFLUENCE_RADIUS) {\n            p.vx += dx * 0.001;\n            p.vy += dy * 0.001;\n        } else {\n            if (Math.abs(p.vx) &gt; POINT_MOVE_SPEED) {\n                p.vx *= 0.999;\n            } else {\n                p.vx = (p.vx &lt; 0 ? -POINT_MOVE_SPEED : POINT_MOVE_SPEED);\n            }\n\n            if (Math.abs(p.vy) &gt; POINT_MOVE_SPEED) {\n                p.vy *= 0.999;\n            } else {\n                p.vy = (p.vy &lt; 0 ? -POINT_MOVE_SPEED : POINT_MOVE_SPEED);\n            }\n        }\n\n        if (timeSinceLastMove &gt; MOUSE_IDLE_THRESHOLD) {\n            if (Math.abs(p.vx) &gt; POINT_MOVE_SPEED) {\n                p.vx *= 0.995;\n            } else {\n                p.vx = (p.vx &lt; 0 ? -POINT_MOVE_SPEED : POINT_MOVE_SPEED);\n            }\n\n            if (Math.abs(p.vy) &gt; POINT_MOVE_SPEED) {\n                p.vy *= 0.995;\n            } else {\n                p.vy = (p.vy &lt; 0 ? -POINT_MOVE_SPEED : POINT_MOVE_SPEED);\n            }\n        }\n    });\n}\n\n\nLast but not least, we will add this mouse influence into our animation sequence.\n\nfunction animate() {\n    createEdges();\n    applyMouseInfluence();\n    drawMesh();\n    updatePoints();\n    requestAnimationFrame(animate);\n}\n\n\nConclusion\n\n\n\nThe final product!\n\nAnd that’s it! Implemented purely in Javascript and transparent, you can add it to any website. Add it on top of content for those with short attention spans too, if need be! My website has tailored some of those magic number values, but those are customizable options left up to you. You can find the complete code at the CodePen link above.\n\nHope you had fun with this one!\n",
      "categories": [],
      "tags": [],
      
      "collection": "projects",
      "url": "/projects/meshy/"
    },{
      
      "title": "Coming Soon...",
      "date": "2019-03-19 00:00:00 +0000",
      "description": "The abstract?\n",
      "content": "Information surrounding the paper.\n",
      "categories": [],
      "tags": [],
      
      "collection": "research",
      "url": "/research/coming-soon/"
    }
  ]
}

